{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-rpd6G83DIJ",
        "colab_type": "text"
      },
      "source": [
        "# Part 1 - Model Training\n",
        "\n",
        "This code looks at creating a linear classification algorithm, assessing if a tumor is malignent or benign. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBi-9FEL3gCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4594a12a-3aaa-45e4-8108-d418e422cbaa"
      },
      "source": [
        "# We first verify the correct version of TF installed\n",
        "# !pip install -q tensorflow-gpu==2.1.0\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNMNxcfr3oIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96a4423e-30eb-42df-9b6c-ad7c804bc91c"
      },
      "source": [
        "# Next, we load the data\n",
        "data = load_breast_cancer()\n",
        "print(\"Data Type:\", type(data))\n",
        "# The data is a Bunch objsect, meaning it is a dictionary, where the keys can be treated as atribus"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Type: <class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWwoF4S_4D2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4da7376a-5b6e-4148-994b-d1ba8be1c311"
      },
      "source": [
        "data.keys()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdwx451c4zZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc01454b-b255-4ef8-9499-b6f73745b54e"
      },
      "source": [
        "data.data.shape # the data.data reffers to the input data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDUack8y406D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3970f953-816a-44f8-ef98-30edc659b0ac"
      },
      "source": [
        "data.target.shape # the data.target reffers to the target/output data, a 1D array of 0s and 1s"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmRaAeVR49ZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e1650a71-3e29-4244-95e7-36dca31085c4"
      },
      "source": [
        "# These ar ethe names of the various inputs and feature\n",
        "print(data.target_names)\n",
        "print(data.feature_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['malignant' 'benign']\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vybJBaK5Rvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKSr8EFi5v7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We scale the data, to make sure the ranges/scales of all the inputs are similar.\n",
        "# We substract the mean and divide by the standard deviation\n",
        "\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "X_test = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "N,D = X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8yRU-HC6RZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d64a112-68f0-4ab4-9f13-2177a5aaaab7"
      },
      "source": [
        "# This is where the model is created\n",
        "# First, a model object is created. This is a Sequential-type object. \n",
        "# The object takes an input, which specifies the shape of the Input, while the Dense takes the input and does a linear transformation to get an output of sieze 1.\n",
        "\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Input(shape=(D,)),\n",
        "     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Alternativelly, we can also define the model (model2) as follows. This allows us to add layers.\n",
        "\n",
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))\n",
        "\n",
        "# The next step is to compile the models.\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model2.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "# Then, we train the two models\n",
        "\n",
        "r = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 200)\n",
        "r2 = model2.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 200)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/200\n",
            "381/381 [==============================] - 0s 928us/sample - loss: 1.0063 - accuracy: 0.4934 - val_loss: 0.8302 - val_accuracy: 0.5532\n",
            "Epoch 2/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.9112 - accuracy: 0.5249 - val_loss: 0.7524 - val_accuracy: 0.5798\n",
            "Epoch 3/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.8238 - accuracy: 0.5669 - val_loss: 0.6830 - val_accuracy: 0.6117\n",
            "Epoch 4/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.7470 - accuracy: 0.6168 - val_loss: 0.6214 - val_accuracy: 0.6755\n",
            "Epoch 5/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.6761 - accuracy: 0.6457 - val_loss: 0.5693 - val_accuracy: 0.6862\n",
            "Epoch 6/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.6167 - accuracy: 0.6798 - val_loss: 0.5228 - val_accuracy: 0.7287\n",
            "Epoch 7/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.5618 - accuracy: 0.7192 - val_loss: 0.4835 - val_accuracy: 0.7606\n",
            "Epoch 8/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.5151 - accuracy: 0.7507 - val_loss: 0.4489 - val_accuracy: 0.7713\n",
            "Epoch 9/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.4732 - accuracy: 0.7900 - val_loss: 0.4193 - val_accuracy: 0.8032\n",
            "Epoch 10/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.4361 - accuracy: 0.8110 - val_loss: 0.3940 - val_accuracy: 0.8032\n",
            "Epoch 11/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.4051 - accuracy: 0.8241 - val_loss: 0.3710 - val_accuracy: 0.8085\n",
            "Epoch 12/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.3754 - accuracy: 0.8399 - val_loss: 0.3520 - val_accuracy: 0.8351\n",
            "Epoch 13/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.3506 - accuracy: 0.8635 - val_loss: 0.3352 - val_accuracy: 0.8457\n",
            "Epoch 14/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.3289 - accuracy: 0.8661 - val_loss: 0.3202 - val_accuracy: 0.8617\n",
            "Epoch 15/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.3091 - accuracy: 0.8766 - val_loss: 0.3071 - val_accuracy: 0.8617\n",
            "Epoch 16/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.2918 - accuracy: 0.8871 - val_loss: 0.2958 - val_accuracy: 0.8723\n",
            "Epoch 17/200\n",
            "381/381 [==============================] - 0s 109us/sample - loss: 0.2767 - accuracy: 0.8950 - val_loss: 0.2858 - val_accuracy: 0.8883\n",
            "Epoch 18/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.2628 - accuracy: 0.9029 - val_loss: 0.2771 - val_accuracy: 0.8830\n",
            "Epoch 19/200\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.2511 - accuracy: 0.9108 - val_loss: 0.2694 - val_accuracy: 0.8830\n",
            "Epoch 20/200\n",
            "381/381 [==============================] - 0s 188us/sample - loss: 0.2405 - accuracy: 0.9160 - val_loss: 0.2625 - val_accuracy: 0.8830\n",
            "Epoch 21/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.2308 - accuracy: 0.9213 - val_loss: 0.2564 - val_accuracy: 0.8936\n",
            "Epoch 22/200\n",
            "381/381 [==============================] - 0s 148us/sample - loss: 0.2227 - accuracy: 0.9239 - val_loss: 0.2508 - val_accuracy: 0.8883\n",
            "Epoch 23/200\n",
            "381/381 [==============================] - 0s 162us/sample - loss: 0.2150 - accuracy: 0.9265 - val_loss: 0.2458 - val_accuracy: 0.9043\n",
            "Epoch 24/200\n",
            "381/381 [==============================] - 0s 154us/sample - loss: 0.2082 - accuracy: 0.9318 - val_loss: 0.2412 - val_accuracy: 0.9043\n",
            "Epoch 25/200\n",
            "381/381 [==============================] - 0s 169us/sample - loss: 0.2022 - accuracy: 0.9344 - val_loss: 0.2370 - val_accuracy: 0.9096\n",
            "Epoch 26/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.1963 - accuracy: 0.9370 - val_loss: 0.2332 - val_accuracy: 0.9096\n",
            "Epoch 27/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1914 - accuracy: 0.9370 - val_loss: 0.2297 - val_accuracy: 0.9096\n",
            "Epoch 28/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1865 - accuracy: 0.9370 - val_loss: 0.2266 - val_accuracy: 0.9043\n",
            "Epoch 29/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.1822 - accuracy: 0.9396 - val_loss: 0.2235 - val_accuracy: 0.9043\n",
            "Epoch 30/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1783 - accuracy: 0.9449 - val_loss: 0.2206 - val_accuracy: 0.9043\n",
            "Epoch 31/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1746 - accuracy: 0.9501 - val_loss: 0.2179 - val_accuracy: 0.9043\n",
            "Epoch 32/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1712 - accuracy: 0.9475 - val_loss: 0.2154 - val_accuracy: 0.9043\n",
            "Epoch 33/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1679 - accuracy: 0.9475 - val_loss: 0.2130 - val_accuracy: 0.9149\n",
            "Epoch 34/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1648 - accuracy: 0.9501 - val_loss: 0.2107 - val_accuracy: 0.9149\n",
            "Epoch 35/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1620 - accuracy: 0.9501 - val_loss: 0.2086 - val_accuracy: 0.9149\n",
            "Epoch 36/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1593 - accuracy: 0.9501 - val_loss: 0.2065 - val_accuracy: 0.9149\n",
            "Epoch 37/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.1568 - accuracy: 0.9501 - val_loss: 0.2045 - val_accuracy: 0.9149\n",
            "Epoch 38/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.1543 - accuracy: 0.9501 - val_loss: 0.2026 - val_accuracy: 0.9149\n",
            "Epoch 39/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.1521 - accuracy: 0.9501 - val_loss: 0.2007 - val_accuracy: 0.9202\n",
            "Epoch 40/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1499 - accuracy: 0.9501 - val_loss: 0.1991 - val_accuracy: 0.9202\n",
            "Epoch 41/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1478 - accuracy: 0.9501 - val_loss: 0.1973 - val_accuracy: 0.9202\n",
            "Epoch 42/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1458 - accuracy: 0.9501 - val_loss: 0.1955 - val_accuracy: 0.9202\n",
            "Epoch 43/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.1439 - accuracy: 0.9528 - val_loss: 0.1938 - val_accuracy: 0.9202\n",
            "Epoch 44/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1420 - accuracy: 0.9528 - val_loss: 0.1923 - val_accuracy: 0.9202\n",
            "Epoch 45/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1403 - accuracy: 0.9528 - val_loss: 0.1907 - val_accuracy: 0.9202\n",
            "Epoch 46/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1386 - accuracy: 0.9528 - val_loss: 0.1892 - val_accuracy: 0.9202\n",
            "Epoch 47/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1369 - accuracy: 0.9528 - val_loss: 0.1878 - val_accuracy: 0.9255\n",
            "Epoch 48/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1354 - accuracy: 0.9528 - val_loss: 0.1863 - val_accuracy: 0.9255\n",
            "Epoch 49/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1338 - accuracy: 0.9528 - val_loss: 0.1850 - val_accuracy: 0.9255\n",
            "Epoch 50/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1324 - accuracy: 0.9528 - val_loss: 0.1835 - val_accuracy: 0.9255\n",
            "Epoch 51/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1310 - accuracy: 0.9528 - val_loss: 0.1823 - val_accuracy: 0.9309\n",
            "Epoch 52/200\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.1296 - accuracy: 0.9528 - val_loss: 0.1809 - val_accuracy: 0.9309\n",
            "Epoch 53/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1282 - accuracy: 0.9528 - val_loss: 0.1796 - val_accuracy: 0.9309\n",
            "Epoch 54/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.1269 - accuracy: 0.9554 - val_loss: 0.1784 - val_accuracy: 0.9309\n",
            "Epoch 55/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.1257 - accuracy: 0.9580 - val_loss: 0.1771 - val_accuracy: 0.9309\n",
            "Epoch 56/200\n",
            "381/381 [==============================] - 0s 167us/sample - loss: 0.1244 - accuracy: 0.9580 - val_loss: 0.1759 - val_accuracy: 0.9309\n",
            "Epoch 57/200\n",
            "381/381 [==============================] - 0s 158us/sample - loss: 0.1232 - accuracy: 0.9580 - val_loss: 0.1747 - val_accuracy: 0.9309\n",
            "Epoch 58/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.1220 - accuracy: 0.9580 - val_loss: 0.1735 - val_accuracy: 0.9309\n",
            "Epoch 59/200\n",
            "381/381 [==============================] - 0s 185us/sample - loss: 0.1209 - accuracy: 0.9580 - val_loss: 0.1724 - val_accuracy: 0.9309\n",
            "Epoch 60/200\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.1198 - accuracy: 0.9580 - val_loss: 0.1712 - val_accuracy: 0.9309\n",
            "Epoch 61/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1187 - accuracy: 0.9606 - val_loss: 0.1701 - val_accuracy: 0.9309\n",
            "Epoch 62/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1176 - accuracy: 0.9606 - val_loss: 0.1692 - val_accuracy: 0.9309\n",
            "Epoch 63/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1166 - accuracy: 0.9606 - val_loss: 0.1680 - val_accuracy: 0.9362\n",
            "Epoch 64/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1156 - accuracy: 0.9606 - val_loss: 0.1671 - val_accuracy: 0.9362\n",
            "Epoch 65/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.1147 - accuracy: 0.9606 - val_loss: 0.1659 - val_accuracy: 0.9362\n",
            "Epoch 66/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1136 - accuracy: 0.9606 - val_loss: 0.1649 - val_accuracy: 0.9362\n",
            "Epoch 67/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.1127 - accuracy: 0.9606 - val_loss: 0.1638 - val_accuracy: 0.9362\n",
            "Epoch 68/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1117 - accuracy: 0.9606 - val_loss: 0.1630 - val_accuracy: 0.9362\n",
            "Epoch 69/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.1108 - accuracy: 0.9606 - val_loss: 0.1620 - val_accuracy: 0.9415\n",
            "Epoch 70/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1100 - accuracy: 0.9606 - val_loss: 0.1610 - val_accuracy: 0.9415\n",
            "Epoch 71/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1091 - accuracy: 0.9606 - val_loss: 0.1600 - val_accuracy: 0.9415\n",
            "Epoch 72/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1082 - accuracy: 0.9606 - val_loss: 0.1591 - val_accuracy: 0.9415\n",
            "Epoch 73/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.1074 - accuracy: 0.9606 - val_loss: 0.1582 - val_accuracy: 0.9415\n",
            "Epoch 74/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.1065 - accuracy: 0.9606 - val_loss: 0.1573 - val_accuracy: 0.9415\n",
            "Epoch 75/200\n",
            "381/381 [==============================] - 0s 151us/sample - loss: 0.1057 - accuracy: 0.9606 - val_loss: 0.1565 - val_accuracy: 0.9415\n",
            "Epoch 76/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.1049 - accuracy: 0.9606 - val_loss: 0.1556 - val_accuracy: 0.9415\n",
            "Epoch 77/200\n",
            "381/381 [==============================] - 0s 154us/sample - loss: 0.1041 - accuracy: 0.9606 - val_loss: 0.1547 - val_accuracy: 0.9415\n",
            "Epoch 78/200\n",
            "381/381 [==============================] - 0s 176us/sample - loss: 0.1034 - accuracy: 0.9606 - val_loss: 0.1539 - val_accuracy: 0.9415\n",
            "Epoch 79/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1026 - accuracy: 0.9606 - val_loss: 0.1530 - val_accuracy: 0.9415\n",
            "Epoch 80/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.1019 - accuracy: 0.9606 - val_loss: 0.1523 - val_accuracy: 0.9415\n",
            "Epoch 81/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1011 - accuracy: 0.9606 - val_loss: 0.1515 - val_accuracy: 0.9415\n",
            "Epoch 82/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1004 - accuracy: 0.9606 - val_loss: 0.1507 - val_accuracy: 0.9415\n",
            "Epoch 83/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0997 - accuracy: 0.9606 - val_loss: 0.1499 - val_accuracy: 0.9468\n",
            "Epoch 84/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0990 - accuracy: 0.9606 - val_loss: 0.1491 - val_accuracy: 0.9468\n",
            "Epoch 85/200\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.0983 - accuracy: 0.9606 - val_loss: 0.1484 - val_accuracy: 0.9468\n",
            "Epoch 86/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0977 - accuracy: 0.9606 - val_loss: 0.1476 - val_accuracy: 0.9468\n",
            "Epoch 87/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0970 - accuracy: 0.9606 - val_loss: 0.1469 - val_accuracy: 0.9521\n",
            "Epoch 88/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0964 - accuracy: 0.9606 - val_loss: 0.1462 - val_accuracy: 0.9574\n",
            "Epoch 89/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0957 - accuracy: 0.9606 - val_loss: 0.1455 - val_accuracy: 0.9574\n",
            "Epoch 90/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0951 - accuracy: 0.9606 - val_loss: 0.1448 - val_accuracy: 0.9574\n",
            "Epoch 91/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0945 - accuracy: 0.9633 - val_loss: 0.1441 - val_accuracy: 0.9574\n",
            "Epoch 92/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0939 - accuracy: 0.9659 - val_loss: 0.1435 - val_accuracy: 0.9574\n",
            "Epoch 93/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0933 - accuracy: 0.9659 - val_loss: 0.1428 - val_accuracy: 0.9574\n",
            "Epoch 94/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0927 - accuracy: 0.9659 - val_loss: 0.1421 - val_accuracy: 0.9574\n",
            "Epoch 95/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0921 - accuracy: 0.9659 - val_loss: 0.1416 - val_accuracy: 0.9574\n",
            "Epoch 96/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0915 - accuracy: 0.9659 - val_loss: 0.1409 - val_accuracy: 0.9574\n",
            "Epoch 97/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0909 - accuracy: 0.9659 - val_loss: 0.1403 - val_accuracy: 0.9574\n",
            "Epoch 98/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0904 - accuracy: 0.9685 - val_loss: 0.1397 - val_accuracy: 0.9574\n",
            "Epoch 99/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0898 - accuracy: 0.9685 - val_loss: 0.1391 - val_accuracy: 0.9574\n",
            "Epoch 100/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.0893 - accuracy: 0.9685 - val_loss: 0.1384 - val_accuracy: 0.9574\n",
            "Epoch 101/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0887 - accuracy: 0.9685 - val_loss: 0.1379 - val_accuracy: 0.9574\n",
            "Epoch 102/200\n",
            "381/381 [==============================] - 0s 153us/sample - loss: 0.0882 - accuracy: 0.9685 - val_loss: 0.1373 - val_accuracy: 0.9574\n",
            "Epoch 103/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0877 - accuracy: 0.9685 - val_loss: 0.1367 - val_accuracy: 0.9574\n",
            "Epoch 104/200\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.0872 - accuracy: 0.9685 - val_loss: 0.1362 - val_accuracy: 0.9574\n",
            "Epoch 105/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0867 - accuracy: 0.9685 - val_loss: 0.1356 - val_accuracy: 0.9574\n",
            "Epoch 106/200\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0862 - accuracy: 0.9685 - val_loss: 0.1351 - val_accuracy: 0.9574\n",
            "Epoch 107/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0857 - accuracy: 0.9685 - val_loss: 0.1346 - val_accuracy: 0.9574\n",
            "Epoch 108/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0852 - accuracy: 0.9685 - val_loss: 0.1341 - val_accuracy: 0.9574\n",
            "Epoch 109/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0847 - accuracy: 0.9738 - val_loss: 0.1336 - val_accuracy: 0.9574\n",
            "Epoch 110/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0842 - accuracy: 0.9790 - val_loss: 0.1330 - val_accuracy: 0.9574\n",
            "Epoch 111/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0837 - accuracy: 0.9790 - val_loss: 0.1325 - val_accuracy: 0.9574\n",
            "Epoch 112/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0833 - accuracy: 0.9790 - val_loss: 0.1320 - val_accuracy: 0.9574\n",
            "Epoch 113/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0828 - accuracy: 0.9790 - val_loss: 0.1316 - val_accuracy: 0.9574\n",
            "Epoch 114/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0824 - accuracy: 0.9790 - val_loss: 0.1311 - val_accuracy: 0.9574\n",
            "Epoch 115/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0819 - accuracy: 0.9790 - val_loss: 0.1306 - val_accuracy: 0.9574\n",
            "Epoch 116/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0815 - accuracy: 0.9790 - val_loss: 0.1301 - val_accuracy: 0.9574\n",
            "Epoch 117/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0811 - accuracy: 0.9790 - val_loss: 0.1297 - val_accuracy: 0.9574\n",
            "Epoch 118/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.0806 - accuracy: 0.9790 - val_loss: 0.1292 - val_accuracy: 0.9574\n",
            "Epoch 119/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0802 - accuracy: 0.9790 - val_loss: 0.1288 - val_accuracy: 0.9574\n",
            "Epoch 120/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0798 - accuracy: 0.9790 - val_loss: 0.1284 - val_accuracy: 0.9574\n",
            "Epoch 121/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0794 - accuracy: 0.9790 - val_loss: 0.1280 - val_accuracy: 0.9574\n",
            "Epoch 122/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.0790 - accuracy: 0.9790 - val_loss: 0.1275 - val_accuracy: 0.9574\n",
            "Epoch 123/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0786 - accuracy: 0.9790 - val_loss: 0.1271 - val_accuracy: 0.9574\n",
            "Epoch 124/200\n",
            "381/381 [==============================] - 0s 159us/sample - loss: 0.0782 - accuracy: 0.9790 - val_loss: 0.1267 - val_accuracy: 0.9574\n",
            "Epoch 125/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0778 - accuracy: 0.9790 - val_loss: 0.1262 - val_accuracy: 0.9574\n",
            "Epoch 126/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0774 - accuracy: 0.9816 - val_loss: 0.1259 - val_accuracy: 0.9574\n",
            "Epoch 127/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0770 - accuracy: 0.9816 - val_loss: 0.1256 - val_accuracy: 0.9574\n",
            "Epoch 128/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0766 - accuracy: 0.9816 - val_loss: 0.1252 - val_accuracy: 0.9574\n",
            "Epoch 129/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0763 - accuracy: 0.9816 - val_loss: 0.1248 - val_accuracy: 0.9574\n",
            "Epoch 130/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0759 - accuracy: 0.9816 - val_loss: 0.1245 - val_accuracy: 0.9574\n",
            "Epoch 131/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0755 - accuracy: 0.9816 - val_loss: 0.1241 - val_accuracy: 0.9574\n",
            "Epoch 132/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0751 - accuracy: 0.9816 - val_loss: 0.1238 - val_accuracy: 0.9628\n",
            "Epoch 133/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0748 - accuracy: 0.9816 - val_loss: 0.1234 - val_accuracy: 0.9628\n",
            "Epoch 134/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0744 - accuracy: 0.9816 - val_loss: 0.1230 - val_accuracy: 0.9628\n",
            "Epoch 135/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0741 - accuracy: 0.9816 - val_loss: 0.1226 - val_accuracy: 0.9628\n",
            "Epoch 136/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0737 - accuracy: 0.9816 - val_loss: 0.1223 - val_accuracy: 0.9628\n",
            "Epoch 137/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.0734 - accuracy: 0.9816 - val_loss: 0.1220 - val_accuracy: 0.9628\n",
            "Epoch 138/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0731 - accuracy: 0.9816 - val_loss: 0.1216 - val_accuracy: 0.9628\n",
            "Epoch 139/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0727 - accuracy: 0.9843 - val_loss: 0.1213 - val_accuracy: 0.9628\n",
            "Epoch 140/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0724 - accuracy: 0.9843 - val_loss: 0.1209 - val_accuracy: 0.9628\n",
            "Epoch 141/200\n",
            "381/381 [==============================] - 0s 153us/sample - loss: 0.0721 - accuracy: 0.9843 - val_loss: 0.1206 - val_accuracy: 0.9628\n",
            "Epoch 142/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0717 - accuracy: 0.9843 - val_loss: 0.1204 - val_accuracy: 0.9628\n",
            "Epoch 143/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0714 - accuracy: 0.9843 - val_loss: 0.1201 - val_accuracy: 0.9628\n",
            "Epoch 144/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0712 - accuracy: 0.9843 - val_loss: 0.1197 - val_accuracy: 0.9628\n",
            "Epoch 145/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0708 - accuracy: 0.9843 - val_loss: 0.1194 - val_accuracy: 0.9628\n",
            "Epoch 146/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0705 - accuracy: 0.9843 - val_loss: 0.1192 - val_accuracy: 0.9628\n",
            "Epoch 147/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0702 - accuracy: 0.9843 - val_loss: 0.1189 - val_accuracy: 0.9628\n",
            "Epoch 148/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0699 - accuracy: 0.9843 - val_loss: 0.1186 - val_accuracy: 0.9628\n",
            "Epoch 149/200\n",
            "381/381 [==============================] - 0s 153us/sample - loss: 0.0696 - accuracy: 0.9843 - val_loss: 0.1184 - val_accuracy: 0.9628\n",
            "Epoch 150/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0693 - accuracy: 0.9843 - val_loss: 0.1181 - val_accuracy: 0.9681\n",
            "Epoch 151/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0690 - accuracy: 0.9843 - val_loss: 0.1178 - val_accuracy: 0.9681\n",
            "Epoch 152/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0687 - accuracy: 0.9843 - val_loss: 0.1176 - val_accuracy: 0.9681\n",
            "Epoch 153/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0685 - accuracy: 0.9843 - val_loss: 0.1172 - val_accuracy: 0.9681\n",
            "Epoch 154/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0682 - accuracy: 0.9843 - val_loss: 0.1170 - val_accuracy: 0.9681\n",
            "Epoch 155/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0679 - accuracy: 0.9843 - val_loss: 0.1168 - val_accuracy: 0.9681\n",
            "Epoch 156/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0676 - accuracy: 0.9843 - val_loss: 0.1165 - val_accuracy: 0.9681\n",
            "Epoch 157/200\n",
            "381/381 [==============================] - 0s 148us/sample - loss: 0.0673 - accuracy: 0.9843 - val_loss: 0.1163 - val_accuracy: 0.9681\n",
            "Epoch 158/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0671 - accuracy: 0.9843 - val_loss: 0.1160 - val_accuracy: 0.9681\n",
            "Epoch 159/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0668 - accuracy: 0.9843 - val_loss: 0.1158 - val_accuracy: 0.9681\n",
            "Epoch 160/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0665 - accuracy: 0.9869 - val_loss: 0.1155 - val_accuracy: 0.9681\n",
            "Epoch 161/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0663 - accuracy: 0.9869 - val_loss: 0.1153 - val_accuracy: 0.9681\n",
            "Epoch 162/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0660 - accuracy: 0.9869 - val_loss: 0.1151 - val_accuracy: 0.9681\n",
            "Epoch 163/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0657 - accuracy: 0.9869 - val_loss: 0.1149 - val_accuracy: 0.9681\n",
            "Epoch 164/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0655 - accuracy: 0.9869 - val_loss: 0.1146 - val_accuracy: 0.9681\n",
            "Epoch 165/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0653 - accuracy: 0.9869 - val_loss: 0.1145 - val_accuracy: 0.9681\n",
            "Epoch 166/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0650 - accuracy: 0.9869 - val_loss: 0.1143 - val_accuracy: 0.9681\n",
            "Epoch 167/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.1140 - val_accuracy: 0.9681\n",
            "Epoch 168/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0645 - accuracy: 0.9869 - val_loss: 0.1138 - val_accuracy: 0.9681\n",
            "Epoch 169/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0643 - accuracy: 0.9869 - val_loss: 0.1136 - val_accuracy: 0.9681\n",
            "Epoch 170/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0640 - accuracy: 0.9869 - val_loss: 0.1134 - val_accuracy: 0.9681\n",
            "Epoch 171/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0638 - accuracy: 0.9869 - val_loss: 0.1132 - val_accuracy: 0.9681\n",
            "Epoch 172/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0636 - accuracy: 0.9869 - val_loss: 0.1130 - val_accuracy: 0.9681\n",
            "Epoch 173/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0633 - accuracy: 0.9869 - val_loss: 0.1128 - val_accuracy: 0.9681\n",
            "Epoch 174/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0631 - accuracy: 0.9869 - val_loss: 0.1126 - val_accuracy: 0.9681\n",
            "Epoch 175/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0629 - accuracy: 0.9869 - val_loss: 0.1124 - val_accuracy: 0.9681\n",
            "Epoch 176/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0627 - accuracy: 0.9869 - val_loss: 0.1122 - val_accuracy: 0.9681\n",
            "Epoch 177/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.0624 - accuracy: 0.9869 - val_loss: 0.1121 - val_accuracy: 0.9681\n",
            "Epoch 178/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.1120 - val_accuracy: 0.9681\n",
            "Epoch 179/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0620 - accuracy: 0.9869 - val_loss: 0.1117 - val_accuracy: 0.9681\n",
            "Epoch 180/200\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0618 - accuracy: 0.9869 - val_loss: 0.1115 - val_accuracy: 0.9681\n",
            "Epoch 181/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.1114 - val_accuracy: 0.9681\n",
            "Epoch 182/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.1112 - val_accuracy: 0.9681\n",
            "Epoch 183/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0611 - accuracy: 0.9869 - val_loss: 0.1111 - val_accuracy: 0.9681\n",
            "Epoch 184/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.1109 - val_accuracy: 0.9681\n",
            "Epoch 185/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.1108 - val_accuracy: 0.9681\n",
            "Epoch 186/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.1105 - val_accuracy: 0.9681\n",
            "Epoch 187/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.1104 - val_accuracy: 0.9681\n",
            "Epoch 188/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0601 - accuracy: 0.9869 - val_loss: 0.1103 - val_accuracy: 0.9681\n",
            "Epoch 189/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0599 - accuracy: 0.9869 - val_loss: 0.1101 - val_accuracy: 0.9681\n",
            "Epoch 190/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.1099 - val_accuracy: 0.9681\n",
            "Epoch 191/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0595 - accuracy: 0.9869 - val_loss: 0.1098 - val_accuracy: 0.9681\n",
            "Epoch 192/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.1096 - val_accuracy: 0.9681\n",
            "Epoch 193/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.1094 - val_accuracy: 0.9681\n",
            "Epoch 194/200\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.1093 - val_accuracy: 0.9681\n",
            "Epoch 195/200\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.1092 - val_accuracy: 0.9681\n",
            "Epoch 196/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0585 - accuracy: 0.9869 - val_loss: 0.1090 - val_accuracy: 0.9681\n",
            "Epoch 197/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.1089 - val_accuracy: 0.9681\n",
            "Epoch 198/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0582 - accuracy: 0.9869 - val_loss: 0.1088 - val_accuracy: 0.9681\n",
            "Epoch 199/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.1087 - val_accuracy: 0.9681\n",
            "Epoch 200/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0578 - accuracy: 0.9869 - val_loss: 0.1085 - val_accuracy: 0.9681\n",
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/200\n",
            "381/381 [==============================] - 0s 1ms/sample - loss: 0.9849 - accuracy: 0.3281 - val_loss: 0.9753 - val_accuracy: 0.3670\n",
            "Epoch 2/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.8930 - accuracy: 0.4094 - val_loss: 0.8907 - val_accuracy: 0.4521\n",
            "Epoch 3/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.8090 - accuracy: 0.4908 - val_loss: 0.8162 - val_accuracy: 0.5053\n",
            "Epoch 4/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.7351 - accuracy: 0.5512 - val_loss: 0.7520 - val_accuracy: 0.5585\n",
            "Epoch 5/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.6726 - accuracy: 0.6168 - val_loss: 0.6963 - val_accuracy: 0.6011\n",
            "Epoch 6/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.6188 - accuracy: 0.6640 - val_loss: 0.6480 - val_accuracy: 0.6383\n",
            "Epoch 7/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.5729 - accuracy: 0.7244 - val_loss: 0.6056 - val_accuracy: 0.6915\n",
            "Epoch 8/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.5332 - accuracy: 0.7585 - val_loss: 0.5689 - val_accuracy: 0.7340\n",
            "Epoch 9/200\n",
            "381/381 [==============================] - 0s 159us/sample - loss: 0.4973 - accuracy: 0.7979 - val_loss: 0.5380 - val_accuracy: 0.7606\n",
            "Epoch 10/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.4674 - accuracy: 0.8189 - val_loss: 0.5100 - val_accuracy: 0.7713\n",
            "Epoch 11/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.4403 - accuracy: 0.8399 - val_loss: 0.4862 - val_accuracy: 0.7872\n",
            "Epoch 12/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.4172 - accuracy: 0.8609 - val_loss: 0.4640 - val_accuracy: 0.8138\n",
            "Epoch 13/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.3955 - accuracy: 0.8740 - val_loss: 0.4444 - val_accuracy: 0.8245\n",
            "Epoch 14/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.3765 - accuracy: 0.8898 - val_loss: 0.4267 - val_accuracy: 0.8351\n",
            "Epoch 15/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.3594 - accuracy: 0.8976 - val_loss: 0.4108 - val_accuracy: 0.8457\n",
            "Epoch 16/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.3439 - accuracy: 0.8976 - val_loss: 0.3960 - val_accuracy: 0.8511\n",
            "Epoch 17/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.3294 - accuracy: 0.9081 - val_loss: 0.3827 - val_accuracy: 0.8564\n",
            "Epoch 18/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.3167 - accuracy: 0.9081 - val_loss: 0.3702 - val_accuracy: 0.8617\n",
            "Epoch 19/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.3045 - accuracy: 0.9108 - val_loss: 0.3593 - val_accuracy: 0.8723\n",
            "Epoch 20/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.2938 - accuracy: 0.9108 - val_loss: 0.3487 - val_accuracy: 0.8723\n",
            "Epoch 21/200\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.2835 - accuracy: 0.9108 - val_loss: 0.3389 - val_accuracy: 0.8723\n",
            "Epoch 22/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.2742 - accuracy: 0.9108 - val_loss: 0.3299 - val_accuracy: 0.8723\n",
            "Epoch 23/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.2653 - accuracy: 0.9134 - val_loss: 0.3218 - val_accuracy: 0.8777\n",
            "Epoch 24/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.2574 - accuracy: 0.9213 - val_loss: 0.3136 - val_accuracy: 0.8830\n",
            "Epoch 25/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.2497 - accuracy: 0.9265 - val_loss: 0.3061 - val_accuracy: 0.8830\n",
            "Epoch 26/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.2426 - accuracy: 0.9265 - val_loss: 0.2989 - val_accuracy: 0.8883\n",
            "Epoch 27/200\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.2358 - accuracy: 0.9291 - val_loss: 0.2925 - val_accuracy: 0.8883\n",
            "Epoch 28/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.2297 - accuracy: 0.9318 - val_loss: 0.2863 - val_accuracy: 0.8883\n",
            "Epoch 29/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.2239 - accuracy: 0.9318 - val_loss: 0.2802 - val_accuracy: 0.8883\n",
            "Epoch 30/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.2182 - accuracy: 0.9318 - val_loss: 0.2747 - val_accuracy: 0.8883\n",
            "Epoch 31/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.2130 - accuracy: 0.9318 - val_loss: 0.2695 - val_accuracy: 0.8883\n",
            "Epoch 32/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.2079 - accuracy: 0.9344 - val_loss: 0.2646 - val_accuracy: 0.8883\n",
            "Epoch 33/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.2033 - accuracy: 0.9344 - val_loss: 0.2599 - val_accuracy: 0.8883\n",
            "Epoch 34/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1989 - accuracy: 0.9344 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
            "Epoch 35/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1946 - accuracy: 0.9344 - val_loss: 0.2512 - val_accuracy: 0.8936\n",
            "Epoch 36/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.1906 - accuracy: 0.9344 - val_loss: 0.2470 - val_accuracy: 0.8936\n",
            "Epoch 37/200\n",
            "381/381 [==============================] - 0s 169us/sample - loss: 0.1867 - accuracy: 0.9370 - val_loss: 0.2429 - val_accuracy: 0.8936\n",
            "Epoch 38/200\n",
            "381/381 [==============================] - 0s 158us/sample - loss: 0.1830 - accuracy: 0.9370 - val_loss: 0.2392 - val_accuracy: 0.8989\n",
            "Epoch 39/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1796 - accuracy: 0.9423 - val_loss: 0.2357 - val_accuracy: 0.9043\n",
            "Epoch 40/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.1763 - accuracy: 0.9423 - val_loss: 0.2321 - val_accuracy: 0.9096\n",
            "Epoch 41/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1730 - accuracy: 0.9423 - val_loss: 0.2289 - val_accuracy: 0.9096\n",
            "Epoch 42/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.1700 - accuracy: 0.9449 - val_loss: 0.2256 - val_accuracy: 0.9096\n",
            "Epoch 43/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.1671 - accuracy: 0.9449 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
            "Epoch 44/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.1642 - accuracy: 0.9449 - val_loss: 0.2196 - val_accuracy: 0.9149\n",
            "Epoch 45/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1615 - accuracy: 0.9449 - val_loss: 0.2169 - val_accuracy: 0.9255\n",
            "Epoch 46/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1590 - accuracy: 0.9475 - val_loss: 0.2141 - val_accuracy: 0.9309\n",
            "Epoch 47/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1564 - accuracy: 0.9475 - val_loss: 0.2115 - val_accuracy: 0.9309\n",
            "Epoch 48/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.1540 - accuracy: 0.9475 - val_loss: 0.2091 - val_accuracy: 0.9309\n",
            "Epoch 49/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.1517 - accuracy: 0.9501 - val_loss: 0.2067 - val_accuracy: 0.9309\n",
            "Epoch 50/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1494 - accuracy: 0.9528 - val_loss: 0.2045 - val_accuracy: 0.9309\n",
            "Epoch 51/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1473 - accuracy: 0.9554 - val_loss: 0.2023 - val_accuracy: 0.9309\n",
            "Epoch 52/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.1452 - accuracy: 0.9580 - val_loss: 0.2000 - val_accuracy: 0.9255\n",
            "Epoch 53/200\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.1432 - accuracy: 0.9580 - val_loss: 0.1979 - val_accuracy: 0.9255\n",
            "Epoch 54/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1412 - accuracy: 0.9580 - val_loss: 0.1957 - val_accuracy: 0.9255\n",
            "Epoch 55/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1394 - accuracy: 0.9606 - val_loss: 0.1938 - val_accuracy: 0.9255\n",
            "Epoch 56/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1375 - accuracy: 0.9606 - val_loss: 0.1918 - val_accuracy: 0.9255\n",
            "Epoch 57/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.1357 - accuracy: 0.9633 - val_loss: 0.1899 - val_accuracy: 0.9255\n",
            "Epoch 58/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1341 - accuracy: 0.9633 - val_loss: 0.1881 - val_accuracy: 0.9255\n",
            "Epoch 59/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1324 - accuracy: 0.9633 - val_loss: 0.1865 - val_accuracy: 0.9255\n",
            "Epoch 60/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1308 - accuracy: 0.9633 - val_loss: 0.1847 - val_accuracy: 0.9255\n",
            "Epoch 61/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.1293 - accuracy: 0.9659 - val_loss: 0.1830 - val_accuracy: 0.9309\n",
            "Epoch 62/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.1277 - accuracy: 0.9659 - val_loss: 0.1813 - val_accuracy: 0.9362\n",
            "Epoch 63/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.1263 - accuracy: 0.9659 - val_loss: 0.1797 - val_accuracy: 0.9362\n",
            "Epoch 64/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.1248 - accuracy: 0.9659 - val_loss: 0.1783 - val_accuracy: 0.9362\n",
            "Epoch 65/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.1235 - accuracy: 0.9659 - val_loss: 0.1767 - val_accuracy: 0.9362\n",
            "Epoch 66/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1221 - accuracy: 0.9711 - val_loss: 0.1755 - val_accuracy: 0.9362\n",
            "Epoch 67/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1208 - accuracy: 0.9711 - val_loss: 0.1742 - val_accuracy: 0.9362\n",
            "Epoch 68/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1196 - accuracy: 0.9738 - val_loss: 0.1726 - val_accuracy: 0.9362\n",
            "Epoch 69/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.1183 - accuracy: 0.9738 - val_loss: 0.1714 - val_accuracy: 0.9362\n",
            "Epoch 70/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1171 - accuracy: 0.9738 - val_loss: 0.1701 - val_accuracy: 0.9362\n",
            "Epoch 71/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.1160 - accuracy: 0.9738 - val_loss: 0.1686 - val_accuracy: 0.9415\n",
            "Epoch 72/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1147 - accuracy: 0.9738 - val_loss: 0.1675 - val_accuracy: 0.9415\n",
            "Epoch 73/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1137 - accuracy: 0.9738 - val_loss: 0.1662 - val_accuracy: 0.9415\n",
            "Epoch 74/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1125 - accuracy: 0.9738 - val_loss: 0.1651 - val_accuracy: 0.9415\n",
            "Epoch 75/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1115 - accuracy: 0.9738 - val_loss: 0.1639 - val_accuracy: 0.9468\n",
            "Epoch 76/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.1104 - accuracy: 0.9738 - val_loss: 0.1630 - val_accuracy: 0.9468\n",
            "Epoch 77/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1094 - accuracy: 0.9738 - val_loss: 0.1617 - val_accuracy: 0.9468\n",
            "Epoch 78/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1085 - accuracy: 0.9738 - val_loss: 0.1606 - val_accuracy: 0.9468\n",
            "Epoch 79/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1075 - accuracy: 0.9738 - val_loss: 0.1595 - val_accuracy: 0.9468\n",
            "Epoch 80/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.1065 - accuracy: 0.9738 - val_loss: 0.1586 - val_accuracy: 0.9468\n",
            "Epoch 81/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1056 - accuracy: 0.9738 - val_loss: 0.1576 - val_accuracy: 0.9468\n",
            "Epoch 82/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1047 - accuracy: 0.9711 - val_loss: 0.1566 - val_accuracy: 0.9468\n",
            "Epoch 83/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.1039 - accuracy: 0.9711 - val_loss: 0.1556 - val_accuracy: 0.9468\n",
            "Epoch 84/200\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.1030 - accuracy: 0.9711 - val_loss: 0.1547 - val_accuracy: 0.9468\n",
            "Epoch 85/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1021 - accuracy: 0.9711 - val_loss: 0.1538 - val_accuracy: 0.9468\n",
            "Epoch 86/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1013 - accuracy: 0.9711 - val_loss: 0.1530 - val_accuracy: 0.9468\n",
            "Epoch 87/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1004 - accuracy: 0.9711 - val_loss: 0.1521 - val_accuracy: 0.9521\n",
            "Epoch 88/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0997 - accuracy: 0.9711 - val_loss: 0.1513 - val_accuracy: 0.9521\n",
            "Epoch 89/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0989 - accuracy: 0.9711 - val_loss: 0.1504 - val_accuracy: 0.9521\n",
            "Epoch 90/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0981 - accuracy: 0.9711 - val_loss: 0.1496 - val_accuracy: 0.9521\n",
            "Epoch 91/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0974 - accuracy: 0.9711 - val_loss: 0.1487 - val_accuracy: 0.9521\n",
            "Epoch 92/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0967 - accuracy: 0.9711 - val_loss: 0.1479 - val_accuracy: 0.9521\n",
            "Epoch 93/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0959 - accuracy: 0.9711 - val_loss: 0.1472 - val_accuracy: 0.9574\n",
            "Epoch 94/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0952 - accuracy: 0.9711 - val_loss: 0.1464 - val_accuracy: 0.9574\n",
            "Epoch 95/200\n",
            "381/381 [==============================] - 0s 186us/sample - loss: 0.0946 - accuracy: 0.9711 - val_loss: 0.1457 - val_accuracy: 0.9574\n",
            "Epoch 96/200\n",
            "381/381 [==============================] - 0s 191us/sample - loss: 0.0939 - accuracy: 0.9711 - val_loss: 0.1450 - val_accuracy: 0.9574\n",
            "Epoch 97/200\n",
            "381/381 [==============================] - 0s 176us/sample - loss: 0.0932 - accuracy: 0.9711 - val_loss: 0.1442 - val_accuracy: 0.9574\n",
            "Epoch 98/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0926 - accuracy: 0.9738 - val_loss: 0.1433 - val_accuracy: 0.9574\n",
            "Epoch 99/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0919 - accuracy: 0.9738 - val_loss: 0.1427 - val_accuracy: 0.9574\n",
            "Epoch 100/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.0913 - accuracy: 0.9738 - val_loss: 0.1421 - val_accuracy: 0.9574\n",
            "Epoch 101/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0907 - accuracy: 0.9738 - val_loss: 0.1414 - val_accuracy: 0.9574\n",
            "Epoch 102/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0901 - accuracy: 0.9738 - val_loss: 0.1407 - val_accuracy: 0.9574\n",
            "Epoch 103/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0895 - accuracy: 0.9738 - val_loss: 0.1400 - val_accuracy: 0.9574\n",
            "Epoch 104/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0889 - accuracy: 0.9738 - val_loss: 0.1394 - val_accuracy: 0.9574\n",
            "Epoch 105/200\n",
            "381/381 [==============================] - 0s 161us/sample - loss: 0.0883 - accuracy: 0.9738 - val_loss: 0.1389 - val_accuracy: 0.9574\n",
            "Epoch 106/200\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.0878 - accuracy: 0.9738 - val_loss: 0.1382 - val_accuracy: 0.9574\n",
            "Epoch 107/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.0872 - accuracy: 0.9738 - val_loss: 0.1376 - val_accuracy: 0.9574\n",
            "Epoch 108/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0867 - accuracy: 0.9764 - val_loss: 0.1369 - val_accuracy: 0.9574\n",
            "Epoch 109/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0861 - accuracy: 0.9764 - val_loss: 0.1363 - val_accuracy: 0.9574\n",
            "Epoch 110/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0856 - accuracy: 0.9764 - val_loss: 0.1358 - val_accuracy: 0.9574\n",
            "Epoch 111/200\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0851 - accuracy: 0.9764 - val_loss: 0.1353 - val_accuracy: 0.9574\n",
            "Epoch 112/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0846 - accuracy: 0.9764 - val_loss: 0.1349 - val_accuracy: 0.9574\n",
            "Epoch 113/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0841 - accuracy: 0.9764 - val_loss: 0.1343 - val_accuracy: 0.9574\n",
            "Epoch 114/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0836 - accuracy: 0.9764 - val_loss: 0.1337 - val_accuracy: 0.9574\n",
            "Epoch 115/200\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.0831 - accuracy: 0.9790 - val_loss: 0.1332 - val_accuracy: 0.9574\n",
            "Epoch 116/200\n",
            "381/381 [==============================] - 0s 175us/sample - loss: 0.0826 - accuracy: 0.9790 - val_loss: 0.1327 - val_accuracy: 0.9574\n",
            "Epoch 117/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0821 - accuracy: 0.9790 - val_loss: 0.1321 - val_accuracy: 0.9574\n",
            "Epoch 118/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0817 - accuracy: 0.9790 - val_loss: 0.1315 - val_accuracy: 0.9574\n",
            "Epoch 119/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0812 - accuracy: 0.9790 - val_loss: 0.1312 - val_accuracy: 0.9574\n",
            "Epoch 120/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0808 - accuracy: 0.9790 - val_loss: 0.1307 - val_accuracy: 0.9574\n",
            "Epoch 121/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0803 - accuracy: 0.9790 - val_loss: 0.1301 - val_accuracy: 0.9574\n",
            "Epoch 122/200\n",
            "381/381 [==============================] - 0s 160us/sample - loss: 0.0799 - accuracy: 0.9790 - val_loss: 0.1296 - val_accuracy: 0.9574\n",
            "Epoch 123/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0795 - accuracy: 0.9790 - val_loss: 0.1292 - val_accuracy: 0.9574\n",
            "Epoch 124/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0790 - accuracy: 0.9790 - val_loss: 0.1287 - val_accuracy: 0.9574\n",
            "Epoch 125/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0786 - accuracy: 0.9816 - val_loss: 0.1283 - val_accuracy: 0.9574\n",
            "Epoch 126/200\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.0782 - accuracy: 0.9816 - val_loss: 0.1280 - val_accuracy: 0.9574\n",
            "Epoch 127/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0778 - accuracy: 0.9816 - val_loss: 0.1274 - val_accuracy: 0.9574\n",
            "Epoch 128/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0774 - accuracy: 0.9816 - val_loss: 0.1270 - val_accuracy: 0.9574\n",
            "Epoch 129/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0770 - accuracy: 0.9816 - val_loss: 0.1265 - val_accuracy: 0.9574\n",
            "Epoch 130/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0766 - accuracy: 0.9816 - val_loss: 0.1261 - val_accuracy: 0.9574\n",
            "Epoch 131/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0762 - accuracy: 0.9816 - val_loss: 0.1257 - val_accuracy: 0.9574\n",
            "Epoch 132/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0758 - accuracy: 0.9843 - val_loss: 0.1253 - val_accuracy: 0.9574\n",
            "Epoch 133/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0755 - accuracy: 0.9843 - val_loss: 0.1248 - val_accuracy: 0.9574\n",
            "Epoch 134/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0751 - accuracy: 0.9843 - val_loss: 0.1246 - val_accuracy: 0.9574\n",
            "Epoch 135/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.0747 - accuracy: 0.9843 - val_loss: 0.1242 - val_accuracy: 0.9574\n",
            "Epoch 136/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.0744 - accuracy: 0.9843 - val_loss: 0.1237 - val_accuracy: 0.9574\n",
            "Epoch 137/200\n",
            "381/381 [==============================] - 0s 165us/sample - loss: 0.0740 - accuracy: 0.9843 - val_loss: 0.1234 - val_accuracy: 0.9574\n",
            "Epoch 138/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0737 - accuracy: 0.9869 - val_loss: 0.1230 - val_accuracy: 0.9574\n",
            "Epoch 139/200\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.0733 - accuracy: 0.9869 - val_loss: 0.1227 - val_accuracy: 0.9574\n",
            "Epoch 140/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0730 - accuracy: 0.9869 - val_loss: 0.1224 - val_accuracy: 0.9574\n",
            "Epoch 141/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0726 - accuracy: 0.9869 - val_loss: 0.1220 - val_accuracy: 0.9574\n",
            "Epoch 142/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0723 - accuracy: 0.9869 - val_loss: 0.1216 - val_accuracy: 0.9574\n",
            "Epoch 143/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0720 - accuracy: 0.9869 - val_loss: 0.1213 - val_accuracy: 0.9574\n",
            "Epoch 144/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0716 - accuracy: 0.9869 - val_loss: 0.1209 - val_accuracy: 0.9574\n",
            "Epoch 145/200\n",
            "381/381 [==============================] - 0s 159us/sample - loss: 0.0713 - accuracy: 0.9869 - val_loss: 0.1207 - val_accuracy: 0.9574\n",
            "Epoch 146/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0710 - accuracy: 0.9869 - val_loss: 0.1203 - val_accuracy: 0.9574\n",
            "Epoch 147/200\n",
            "381/381 [==============================] - 0s 151us/sample - loss: 0.0707 - accuracy: 0.9869 - val_loss: 0.1199 - val_accuracy: 0.9574\n",
            "Epoch 148/200\n",
            "381/381 [==============================] - 0s 151us/sample - loss: 0.0704 - accuracy: 0.9869 - val_loss: 0.1196 - val_accuracy: 0.9574\n",
            "Epoch 149/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0701 - accuracy: 0.9869 - val_loss: 0.1193 - val_accuracy: 0.9574\n",
            "Epoch 150/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0698 - accuracy: 0.9869 - val_loss: 0.1190 - val_accuracy: 0.9574\n",
            "Epoch 151/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0695 - accuracy: 0.9869 - val_loss: 0.1188 - val_accuracy: 0.9574\n",
            "Epoch 152/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0692 - accuracy: 0.9869 - val_loss: 0.1184 - val_accuracy: 0.9574\n",
            "Epoch 153/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0689 - accuracy: 0.9869 - val_loss: 0.1180 - val_accuracy: 0.9574\n",
            "Epoch 154/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0686 - accuracy: 0.9869 - val_loss: 0.1178 - val_accuracy: 0.9574\n",
            "Epoch 155/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0683 - accuracy: 0.9869 - val_loss: 0.1175 - val_accuracy: 0.9574\n",
            "Epoch 156/200\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.0680 - accuracy: 0.9869 - val_loss: 0.1173 - val_accuracy: 0.9574\n",
            "Epoch 157/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0677 - accuracy: 0.9869 - val_loss: 0.1169 - val_accuracy: 0.9574\n",
            "Epoch 158/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0675 - accuracy: 0.9869 - val_loss: 0.1166 - val_accuracy: 0.9574\n",
            "Epoch 159/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0672 - accuracy: 0.9869 - val_loss: 0.1164 - val_accuracy: 0.9574\n",
            "Epoch 160/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0669 - accuracy: 0.9869 - val_loss: 0.1160 - val_accuracy: 0.9574\n",
            "Epoch 161/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0666 - accuracy: 0.9869 - val_loss: 0.1158 - val_accuracy: 0.9574\n",
            "Epoch 162/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0664 - accuracy: 0.9869 - val_loss: 0.1156 - val_accuracy: 0.9574\n",
            "Epoch 163/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0661 - accuracy: 0.9869 - val_loss: 0.1153 - val_accuracy: 0.9574\n",
            "Epoch 164/200\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.0658 - accuracy: 0.9869 - val_loss: 0.1150 - val_accuracy: 0.9574\n",
            "Epoch 165/200\n",
            "381/381 [==============================] - 0s 165us/sample - loss: 0.0656 - accuracy: 0.9869 - val_loss: 0.1147 - val_accuracy: 0.9574\n",
            "Epoch 166/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0653 - accuracy: 0.9869 - val_loss: 0.1145 - val_accuracy: 0.9574\n",
            "Epoch 167/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0651 - accuracy: 0.9869 - val_loss: 0.1143 - val_accuracy: 0.9574\n",
            "Epoch 168/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.1140 - val_accuracy: 0.9574\n",
            "Epoch 169/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0646 - accuracy: 0.9869 - val_loss: 0.1138 - val_accuracy: 0.9628\n",
            "Epoch 170/200\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.0643 - accuracy: 0.9869 - val_loss: 0.1134 - val_accuracy: 0.9628\n",
            "Epoch 171/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0641 - accuracy: 0.9869 - val_loss: 0.1132 - val_accuracy: 0.9628\n",
            "Epoch 172/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0639 - accuracy: 0.9869 - val_loss: 0.1130 - val_accuracy: 0.9628\n",
            "Epoch 173/200\n",
            "381/381 [==============================] - 0s 164us/sample - loss: 0.0636 - accuracy: 0.9869 - val_loss: 0.1127 - val_accuracy: 0.9628\n",
            "Epoch 174/200\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.0634 - accuracy: 0.9869 - val_loss: 0.1126 - val_accuracy: 0.9628\n",
            "Epoch 175/200\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.0631 - accuracy: 0.9869 - val_loss: 0.1123 - val_accuracy: 0.9628\n",
            "Epoch 176/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0629 - accuracy: 0.9869 - val_loss: 0.1122 - val_accuracy: 0.9628\n",
            "Epoch 177/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0627 - accuracy: 0.9869 - val_loss: 0.1120 - val_accuracy: 0.9628\n",
            "Epoch 178/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.1116 - val_accuracy: 0.9628\n",
            "Epoch 179/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.1114 - val_accuracy: 0.9628\n",
            "Epoch 180/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0620 - accuracy: 0.9869 - val_loss: 0.1111 - val_accuracy: 0.9628\n",
            "Epoch 181/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0618 - accuracy: 0.9869 - val_loss: 0.1111 - val_accuracy: 0.9628\n",
            "Epoch 182/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.1108 - val_accuracy: 0.9628\n",
            "Epoch 183/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.1106 - val_accuracy: 0.9628\n",
            "Epoch 184/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0612 - accuracy: 0.9869 - val_loss: 0.1104 - val_accuracy: 0.9628\n",
            "Epoch 185/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.1102 - val_accuracy: 0.9681\n",
            "Epoch 186/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.1101 - val_accuracy: 0.9628\n",
            "Epoch 187/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.1099 - val_accuracy: 0.9681\n",
            "Epoch 188/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.1096 - val_accuracy: 0.9681\n",
            "Epoch 189/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0601 - accuracy: 0.9869 - val_loss: 0.1093 - val_accuracy: 0.9681\n",
            "Epoch 190/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0599 - accuracy: 0.9869 - val_loss: 0.1093 - val_accuracy: 0.9681\n",
            "Epoch 191/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.1090 - val_accuracy: 0.9681\n",
            "Epoch 192/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0595 - accuracy: 0.9869 - val_loss: 0.1089 - val_accuracy: 0.9681\n",
            "Epoch 193/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.1087 - val_accuracy: 0.9681\n",
            "Epoch 194/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.1085 - val_accuracy: 0.9681\n",
            "Epoch 195/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.1083 - val_accuracy: 0.9681\n",
            "Epoch 196/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.1082 - val_accuracy: 0.9681\n",
            "Epoch 197/200\n",
            "381/381 [==============================] - 0s 151us/sample - loss: 0.0585 - accuracy: 0.9869 - val_loss: 0.1080 - val_accuracy: 0.9681\n",
            "Epoch 198/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0583 - accuracy: 0.9869 - val_loss: 0.1078 - val_accuracy: 0.9681\n",
            "Epoch 199/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0582 - accuracy: 0.9869 - val_loss: 0.1076 - val_accuracy: 0.9681\n",
            "Epoch 200/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.1075 - val_accuracy: 0.9734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaACKIgY93Ya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "21cdb31d-d52c-4200-c481-9e1a17b03195"
      },
      "source": [
        "# We now evaluate the model\n",
        "\n",
        "print(\"Model1:\")\n",
        "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
        "print(\"Test score:\", model.evaluate(X_test, y_test))\n",
        "\n",
        "print(\"Model2:\")\n",
        "print(\"Train score:\", model2.evaluate(X_train, y_train))\n",
        "print(\"Test score:\", model2.evaluate(X_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model1:\n",
            "381/381 [==============================] - 0s 68us/sample - loss: 0.0577 - accuracy: 0.9869\n",
            "Train score: [0.05769141929669017, 0.98687667]\n",
            "188/188 [==============================] - 0s 81us/sample - loss: 0.1085 - accuracy: 0.9681\n",
            "Test score: [0.10848318183041633, 0.9680851]\n",
            "Model2:\n",
            "381/381 [==============================] - 0s 65us/sample - loss: 0.0578 - accuracy: 0.9869\n",
            "Train score: [0.05784998660090714, 0.98687667]\n",
            "188/188 [==============================] - 0s 93us/sample - loss: 0.1075 - accuracy: 0.9734\n",
            "Test score: [0.10749210306304566, 0.9734042]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pyU8jRx-L8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9dc63e3c-946d-434a-844f-fd8f67770b68"
      },
      "source": [
        "# The obtained accuracty is about 97% on both the train and test sets, for both models.\n",
        "# We now plot what has been returned by the fit function, as weel as the accuracy.\n",
        "\n",
        "# Plot what's returned by model.fit()\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.title(\"Model1\")\n",
        "plt.legend()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fad004ba828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6CIiOUKBLiKSIxToIiI54v8D/yHzxQUNEFIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clFkOabM-rVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "efba4738-0991-4c1b-8136-d98244eb47c3"
      },
      "source": [
        "plt.plot(r2.history['loss'], label='loss')\n",
        "plt.plot(r2.history['val_loss'], label='val_loss')\n",
        "plt.title(\"Model2\")\n",
        "plt.legend()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fad003f9710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMeCHj2k-w9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a35573aa-6496-43f8-e849-3e883042a0cc"
      },
      "source": [
        "# Plot the accuracy too\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fad00474cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0EVEUoQCXUQkRfwPkkR+ExQtnvYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mUiSSCq-7Ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ff4a038d-7fd1-40ce-847b-0e62601e364b"
      },
      "source": [
        "\n",
        "plt.plot(r2.history['accuracy'], label='acc')\n",
        "plt.plot(r2.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7facea1550b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OwdPcSx-91D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}