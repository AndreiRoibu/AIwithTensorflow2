# -*- coding: utf-8 -*-
"""ANN_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hD7M0ceeEoqsCTIX9m4PkLn9EJveTcUt
"""

# Commented out IPython magic to ensure Python compatibility.
# We first verify the correct version of TF installed
# !pip install -q tensorflow-gpu==2.1.0

try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
print(tf.__version__)
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Then, we load the data
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
print(X_train.shape)
# Then, we normalize the input data, by scaling them to be between [0,1]
X_train, X_test = X_train / 255.0, X_test / 255.0

# This is where we build the model
# The first layer flattens the data from Nx28x28 to Nx784
# Then we have a dense layer of size 128 with a Relu activation
# We add Dropout regularization with a dropout percentage of 20%

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape = (28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Next, we compile the model, with default settings
model.compile(
    optimizer='adam',
    loss = 'sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# We print out a summery of our model
model.summary()

tf.keras.utils.plot_model(model, to_file = './drive/My Drive/Tensorflow 2.0 Course/Feedforward Artificial Neural Networks/models/MNIST.png')

# We create a ModelCheckpoint function for keeping track of the accuracy
import os
!pip install -q pyyaml h5py

if not os.path.exists('./drive/My Drive/Tensorflow 2.0 Course/Feedforward Artificial Neural Networks/models'):
  os.mkdir('./drive/My Drive/Tensorflow 2.0 Course/Feedforward Artificial Neural Networks/models')

checkpoint_path = "./drive/My Drive/Tensorflow 2.0 Course/Feedforward Artificial Neural Networks/models/MNIST.h5"
checkpoint_dir = os.path.dirname(checkpoint_path)

ModelCheckpoint = [tf.keras.callbacks.ModelCheckpoint(
    # filepath = 'content/drive/My Drive/Tensorflow 2.0 Course/Feedforward Artificial Neural Networks/models/MNIST.cpkt',
    filepath = checkpoint_path,
    monitor='val_loss',
    mode = 'min',
    save_best_only = True,
)]

results = model.fit(
    X_train,
    y_train,
    validation_data=(X_test, y_test),
    epochs = 10,
    callbacks = ModelCheckpoint,
)

# Plot the loss per iteration
plt.plot(results.history['loss'], label='loss')
plt.plot(results.history['val_loss'], label='validation loss')
plt.legend()

# Plot the accuracy per iteration
plt.plot(results.history['accuracy'], label='acc')
plt.plot(results.history['val_accuracy'], label='validation accuracy')
plt.legend()

# Evaluate the model
print(model.evaluate(X_test, y_test))

# Plot the confusion matrix
from sklearn.metrics import confusion_matrix
import itertools

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):
    """ This function prints and plots the confusion matrix. Normalization can be applied
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print('Normalized confusion matrix!')
    else:
        print('Confusion matrix withouth normalization!')

    print (cm)

    plt.imshow(cm, interpolation= 'nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    threshold = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i,j]>threshold else "black")
    
    plt.tight_layout()
    plt.ylabel("True Lable")
    plt.xlabel("Predicted Label")
    plt.show()

p_test = model.predict(X_test).argmax(axis=1)
cm = confusion_matrix(y_test, p_test)
plot_confusion_matrix(cm, list(range(10)))

# We show some of the misclassified examples
misclassified_index = np.where(p_test != y_test)[0]
i = np.random.choice(misclassified_index)
plt.imshow(X_test[i],cmap='gray')
plt.title("True label: %s || Predicted: %s" %(y_test[i], p_test[i]))

