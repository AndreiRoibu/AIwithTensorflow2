{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-rpd6G83DIJ",
        "colab_type": "text"
      },
      "source": [
        "# Part 1 - Model Training\n",
        "\n",
        "This code looks at creating a linear classification algorithm, assessing if a tumor is malignent or benign. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBi-9FEL3gCo",
        "colab_type": "code",
        "outputId": "868c2dc1-334f-4d85-d166-827af3e9d24e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# We first verify the correct version of TF installed\n",
        "# !pip install -q tensorflow-gpu==2.1.0\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNMNxcfr3oIB",
        "colab_type": "code",
        "outputId": "ba97433b-625f-475a-aed2-c44b3c6d5512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Next, we load the data\n",
        "data = load_breast_cancer()\n",
        "print(\"Data Type:\", type(data))\n",
        "# The data is a Bunch objsect, meaning it is a dictionary, where the keys can be treated as atribus"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Type: <class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWwoF4S_4D2m",
        "colab_type": "code",
        "outputId": "40441dfb-68a2-40a8-d387-1315335ca651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.keys()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdwx451c4zZW",
        "colab_type": "code",
        "outputId": "d773fcfa-8d56-4a27-9a9e-e6d8f207f78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.data.shape # the data.data reffers to the input data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDUack8y406D",
        "colab_type": "code",
        "outputId": "130434af-d19a-456c-c270-1894e2baeeb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.target.shape # the data.target reffers to the target/output data, a 1D array of 0s and 1s"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmRaAeVR49ZF",
        "colab_type": "code",
        "outputId": "87110d0e-a6b6-41b4-835b-ca7db7378047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# These ar ethe names of the various inputs and feature\n",
        "print(data.target_names)\n",
        "print(data.feature_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['malignant' 'benign']\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vybJBaK5Rvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKSr8EFi5v7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We scale the data, to make sure the ranges/scales of all the inputs are similar.\n",
        "# We substract the mean and divide by the standard deviation\n",
        "\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "X_test = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "N,D = X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8yRU-HC6RZi",
        "colab_type": "code",
        "outputId": "93a3132a-f2db-4217-a487-f7d5d51d5762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# This is where the model is created\n",
        "# First, a model object is created. This is a Sequential-type object. \n",
        "# The object takes an input, which specifies the shape of the Input, while the Dense takes the input and does a linear transformation to get an output of sieze 1.\n",
        "\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Input(shape=(D,)),\n",
        "     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Alternativelly, we can also define the model (model2) as follows. This allows us to add layers.\n",
        "\n",
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))\n",
        "\n",
        "# The next step is to compile the models.\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model2.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "# Then, we train the two models\n",
        "\n",
        "r = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 200)\n",
        "r2 = model2.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 200)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/200\n",
            "381/381 [==============================] - 2s 6ms/sample - loss: 0.5294 - accuracy: 0.7638 - val_loss: 0.4534 - val_accuracy: 0.8298\n",
            "Epoch 2/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.4778 - accuracy: 0.8110 - val_loss: 0.4109 - val_accuracy: 0.8564\n",
            "Epoch 3/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.4347 - accuracy: 0.8373 - val_loss: 0.3751 - val_accuracy: 0.8830\n",
            "Epoch 4/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.3964 - accuracy: 0.8609 - val_loss: 0.3464 - val_accuracy: 0.8936\n",
            "Epoch 5/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.3655 - accuracy: 0.8819 - val_loss: 0.3225 - val_accuracy: 0.9096\n",
            "Epoch 6/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.3399 - accuracy: 0.9055 - val_loss: 0.3022 - val_accuracy: 0.9202\n",
            "Epoch 7/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.3181 - accuracy: 0.9134 - val_loss: 0.2849 - val_accuracy: 0.9255\n",
            "Epoch 8/200\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.2988 - accuracy: 0.9186 - val_loss: 0.2705 - val_accuracy: 0.9309\n",
            "Epoch 9/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.2829 - accuracy: 0.9239 - val_loss: 0.2577 - val_accuracy: 0.9255\n",
            "Epoch 10/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.2689 - accuracy: 0.9265 - val_loss: 0.2465 - val_accuracy: 0.9309\n",
            "Epoch 11/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.2565 - accuracy: 0.9344 - val_loss: 0.2368 - val_accuracy: 0.9309\n",
            "Epoch 12/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.2456 - accuracy: 0.9370 - val_loss: 0.2281 - val_accuracy: 0.9309\n",
            "Epoch 13/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.2360 - accuracy: 0.9475 - val_loss: 0.2203 - val_accuracy: 0.9255\n",
            "Epoch 14/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.2270 - accuracy: 0.9475 - val_loss: 0.2134 - val_accuracy: 0.9309\n",
            "Epoch 15/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.2193 - accuracy: 0.9475 - val_loss: 0.2071 - val_accuracy: 0.9309\n",
            "Epoch 16/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.2123 - accuracy: 0.9475 - val_loss: 0.2013 - val_accuracy: 0.9362\n",
            "Epoch 17/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.2058 - accuracy: 0.9475 - val_loss: 0.1958 - val_accuracy: 0.9362\n",
            "Epoch 18/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1996 - accuracy: 0.9475 - val_loss: 0.1910 - val_accuracy: 0.9362\n",
            "Epoch 19/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.1941 - accuracy: 0.9475 - val_loss: 0.1865 - val_accuracy: 0.9415\n",
            "Epoch 20/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1890 - accuracy: 0.9501 - val_loss: 0.1823 - val_accuracy: 0.9415\n",
            "Epoch 21/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.1841 - accuracy: 0.9501 - val_loss: 0.1786 - val_accuracy: 0.9415\n",
            "Epoch 22/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1797 - accuracy: 0.9501 - val_loss: 0.1750 - val_accuracy: 0.9521\n",
            "Epoch 23/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1757 - accuracy: 0.9501 - val_loss: 0.1714 - val_accuracy: 0.9521\n",
            "Epoch 24/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1716 - accuracy: 0.9528 - val_loss: 0.1684 - val_accuracy: 0.9521\n",
            "Epoch 25/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1679 - accuracy: 0.9528 - val_loss: 0.1654 - val_accuracy: 0.9521\n",
            "Epoch 26/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1646 - accuracy: 0.9554 - val_loss: 0.1625 - val_accuracy: 0.9521\n",
            "Epoch 27/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1612 - accuracy: 0.9528 - val_loss: 0.1599 - val_accuracy: 0.9521\n",
            "Epoch 28/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.1582 - accuracy: 0.9580 - val_loss: 0.1575 - val_accuracy: 0.9521\n",
            "Epoch 29/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.1553 - accuracy: 0.9580 - val_loss: 0.1551 - val_accuracy: 0.9521\n",
            "Epoch 30/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1525 - accuracy: 0.9606 - val_loss: 0.1530 - val_accuracy: 0.9521\n",
            "Epoch 31/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1498 - accuracy: 0.9606 - val_loss: 0.1510 - val_accuracy: 0.9574\n",
            "Epoch 32/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1474 - accuracy: 0.9606 - val_loss: 0.1489 - val_accuracy: 0.9574\n",
            "Epoch 33/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1450 - accuracy: 0.9606 - val_loss: 0.1471 - val_accuracy: 0.9574\n",
            "Epoch 34/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1427 - accuracy: 0.9606 - val_loss: 0.1453 - val_accuracy: 0.9574\n",
            "Epoch 35/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.1405 - accuracy: 0.9606 - val_loss: 0.1436 - val_accuracy: 0.9574\n",
            "Epoch 36/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1384 - accuracy: 0.9606 - val_loss: 0.1420 - val_accuracy: 0.9574\n",
            "Epoch 37/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.1365 - accuracy: 0.9606 - val_loss: 0.1404 - val_accuracy: 0.9574\n",
            "Epoch 38/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.1345 - accuracy: 0.9606 - val_loss: 0.1390 - val_accuracy: 0.9574\n",
            "Epoch 39/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.1327 - accuracy: 0.9633 - val_loss: 0.1376 - val_accuracy: 0.9574\n",
            "Epoch 40/200\n",
            "381/381 [==============================] - 0s 164us/sample - loss: 0.1309 - accuracy: 0.9659 - val_loss: 0.1363 - val_accuracy: 0.9574\n",
            "Epoch 41/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1292 - accuracy: 0.9685 - val_loss: 0.1351 - val_accuracy: 0.9574\n",
            "Epoch 42/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1276 - accuracy: 0.9685 - val_loss: 0.1340 - val_accuracy: 0.9574\n",
            "Epoch 43/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1260 - accuracy: 0.9685 - val_loss: 0.1328 - val_accuracy: 0.9574\n",
            "Epoch 44/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1245 - accuracy: 0.9711 - val_loss: 0.1317 - val_accuracy: 0.9574\n",
            "Epoch 45/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1231 - accuracy: 0.9711 - val_loss: 0.1307 - val_accuracy: 0.9574\n",
            "Epoch 46/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.1216 - accuracy: 0.9711 - val_loss: 0.1296 - val_accuracy: 0.9628\n",
            "Epoch 47/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1203 - accuracy: 0.9711 - val_loss: 0.1286 - val_accuracy: 0.9628\n",
            "Epoch 48/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.1189 - accuracy: 0.9738 - val_loss: 0.1277 - val_accuracy: 0.9628\n",
            "Epoch 49/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.1177 - accuracy: 0.9738 - val_loss: 0.1268 - val_accuracy: 0.9628\n",
            "Epoch 50/200\n",
            "381/381 [==============================] - 0s 183us/sample - loss: 0.1165 - accuracy: 0.9738 - val_loss: 0.1259 - val_accuracy: 0.9628\n",
            "Epoch 51/200\n",
            "381/381 [==============================] - 0s 189us/sample - loss: 0.1152 - accuracy: 0.9738 - val_loss: 0.1251 - val_accuracy: 0.9628\n",
            "Epoch 52/200\n",
            "381/381 [==============================] - 0s 171us/sample - loss: 0.1141 - accuracy: 0.9738 - val_loss: 0.1244 - val_accuracy: 0.9628\n",
            "Epoch 53/200\n",
            "381/381 [==============================] - 0s 170us/sample - loss: 0.1130 - accuracy: 0.9738 - val_loss: 0.1235 - val_accuracy: 0.9628\n",
            "Epoch 54/200\n",
            "381/381 [==============================] - 0s 166us/sample - loss: 0.1119 - accuracy: 0.9738 - val_loss: 0.1228 - val_accuracy: 0.9628\n",
            "Epoch 55/200\n",
            "381/381 [==============================] - 0s 163us/sample - loss: 0.1108 - accuracy: 0.9738 - val_loss: 0.1221 - val_accuracy: 0.9628\n",
            "Epoch 56/200\n",
            "381/381 [==============================] - 0s 172us/sample - loss: 0.1098 - accuracy: 0.9738 - val_loss: 0.1215 - val_accuracy: 0.9628\n",
            "Epoch 57/200\n",
            "381/381 [==============================] - 0s 162us/sample - loss: 0.1088 - accuracy: 0.9738 - val_loss: 0.1208 - val_accuracy: 0.9628\n",
            "Epoch 58/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.1078 - accuracy: 0.9738 - val_loss: 0.1201 - val_accuracy: 0.9628\n",
            "Epoch 59/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1068 - accuracy: 0.9738 - val_loss: 0.1195 - val_accuracy: 0.9628\n",
            "Epoch 60/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1060 - accuracy: 0.9738 - val_loss: 0.1189 - val_accuracy: 0.9628\n",
            "Epoch 61/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.1050 - accuracy: 0.9738 - val_loss: 0.1183 - val_accuracy: 0.9628\n",
            "Epoch 62/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1041 - accuracy: 0.9738 - val_loss: 0.1178 - val_accuracy: 0.9628\n",
            "Epoch 63/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1033 - accuracy: 0.9738 - val_loss: 0.1173 - val_accuracy: 0.9628\n",
            "Epoch 64/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1024 - accuracy: 0.9738 - val_loss: 0.1168 - val_accuracy: 0.9628\n",
            "Epoch 65/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.1016 - accuracy: 0.9738 - val_loss: 0.1163 - val_accuracy: 0.9628\n",
            "Epoch 66/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.1009 - accuracy: 0.9738 - val_loss: 0.1158 - val_accuracy: 0.9628\n",
            "Epoch 67/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1001 - accuracy: 0.9738 - val_loss: 0.1153 - val_accuracy: 0.9628\n",
            "Epoch 68/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0993 - accuracy: 0.9764 - val_loss: 0.1149 - val_accuracy: 0.9628\n",
            "Epoch 69/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0986 - accuracy: 0.9764 - val_loss: 0.1144 - val_accuracy: 0.9628\n",
            "Epoch 70/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0978 - accuracy: 0.9764 - val_loss: 0.1140 - val_accuracy: 0.9628\n",
            "Epoch 71/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0971 - accuracy: 0.9764 - val_loss: 0.1136 - val_accuracy: 0.9628\n",
            "Epoch 72/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0965 - accuracy: 0.9764 - val_loss: 0.1133 - val_accuracy: 0.9628\n",
            "Epoch 73/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0958 - accuracy: 0.9764 - val_loss: 0.1129 - val_accuracy: 0.9628\n",
            "Epoch 74/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0951 - accuracy: 0.9764 - val_loss: 0.1125 - val_accuracy: 0.9628\n",
            "Epoch 75/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0945 - accuracy: 0.9764 - val_loss: 0.1122 - val_accuracy: 0.9628\n",
            "Epoch 76/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0938 - accuracy: 0.9764 - val_loss: 0.1119 - val_accuracy: 0.9628\n",
            "Epoch 77/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0932 - accuracy: 0.9764 - val_loss: 0.1116 - val_accuracy: 0.9628\n",
            "Epoch 78/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0926 - accuracy: 0.9764 - val_loss: 0.1112 - val_accuracy: 0.9628\n",
            "Epoch 79/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0920 - accuracy: 0.9764 - val_loss: 0.1109 - val_accuracy: 0.9628\n",
            "Epoch 80/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0914 - accuracy: 0.9764 - val_loss: 0.1106 - val_accuracy: 0.9628\n",
            "Epoch 81/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0908 - accuracy: 0.9764 - val_loss: 0.1104 - val_accuracy: 0.9628\n",
            "Epoch 82/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0903 - accuracy: 0.9764 - val_loss: 0.1101 - val_accuracy: 0.9628\n",
            "Epoch 83/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0898 - accuracy: 0.9764 - val_loss: 0.1098 - val_accuracy: 0.9628\n",
            "Epoch 84/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0892 - accuracy: 0.9764 - val_loss: 0.1096 - val_accuracy: 0.9628\n",
            "Epoch 85/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0887 - accuracy: 0.9764 - val_loss: 0.1093 - val_accuracy: 0.9628\n",
            "Epoch 86/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0882 - accuracy: 0.9764 - val_loss: 0.1090 - val_accuracy: 0.9628\n",
            "Epoch 87/200\n",
            "381/381 [==============================] - 0s 174us/sample - loss: 0.0876 - accuracy: 0.9816 - val_loss: 0.1088 - val_accuracy: 0.9628\n",
            "Epoch 88/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0871 - accuracy: 0.9816 - val_loss: 0.1086 - val_accuracy: 0.9628\n",
            "Epoch 89/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0867 - accuracy: 0.9816 - val_loss: 0.1084 - val_accuracy: 0.9628\n",
            "Epoch 90/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0862 - accuracy: 0.9816 - val_loss: 0.1082 - val_accuracy: 0.9628\n",
            "Epoch 91/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0857 - accuracy: 0.9816 - val_loss: 0.1080 - val_accuracy: 0.9628\n",
            "Epoch 92/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0853 - accuracy: 0.9816 - val_loss: 0.1078 - val_accuracy: 0.9628\n",
            "Epoch 93/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0847 - accuracy: 0.9816 - val_loss: 0.1076 - val_accuracy: 0.9628\n",
            "Epoch 94/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0843 - accuracy: 0.9816 - val_loss: 0.1074 - val_accuracy: 0.9628\n",
            "Epoch 95/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0838 - accuracy: 0.9816 - val_loss: 0.1073 - val_accuracy: 0.9628\n",
            "Epoch 96/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0834 - accuracy: 0.9816 - val_loss: 0.1071 - val_accuracy: 0.9628\n",
            "Epoch 97/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0830 - accuracy: 0.9816 - val_loss: 0.1070 - val_accuracy: 0.9628\n",
            "Epoch 98/200\n",
            "381/381 [==============================] - 0s 158us/sample - loss: 0.0826 - accuracy: 0.9816 - val_loss: 0.1069 - val_accuracy: 0.9628\n",
            "Epoch 99/200\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.0822 - accuracy: 0.9816 - val_loss: 0.1066 - val_accuracy: 0.9628\n",
            "Epoch 100/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0817 - accuracy: 0.9816 - val_loss: 0.1065 - val_accuracy: 0.9628\n",
            "Epoch 101/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0813 - accuracy: 0.9816 - val_loss: 0.1064 - val_accuracy: 0.9628\n",
            "Epoch 102/200\n",
            "381/381 [==============================] - 0s 167us/sample - loss: 0.0809 - accuracy: 0.9816 - val_loss: 0.1063 - val_accuracy: 0.9628\n",
            "Epoch 103/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0806 - accuracy: 0.9816 - val_loss: 0.1061 - val_accuracy: 0.9628\n",
            "Epoch 104/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0802 - accuracy: 0.9816 - val_loss: 0.1060 - val_accuracy: 0.9628\n",
            "Epoch 105/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0798 - accuracy: 0.9816 - val_loss: 0.1059 - val_accuracy: 0.9628\n",
            "Epoch 106/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0794 - accuracy: 0.9816 - val_loss: 0.1058 - val_accuracy: 0.9628\n",
            "Epoch 107/200\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.0791 - accuracy: 0.9843 - val_loss: 0.1056 - val_accuracy: 0.9628\n",
            "Epoch 108/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0787 - accuracy: 0.9843 - val_loss: 0.1056 - val_accuracy: 0.9628\n",
            "Epoch 109/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0783 - accuracy: 0.9843 - val_loss: 0.1055 - val_accuracy: 0.9628\n",
            "Epoch 110/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0780 - accuracy: 0.9843 - val_loss: 0.1054 - val_accuracy: 0.9628\n",
            "Epoch 111/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0776 - accuracy: 0.9843 - val_loss: 0.1053 - val_accuracy: 0.9628\n",
            "Epoch 112/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0773 - accuracy: 0.9843 - val_loss: 0.1052 - val_accuracy: 0.9628\n",
            "Epoch 113/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0770 - accuracy: 0.9843 - val_loss: 0.1051 - val_accuracy: 0.9628\n",
            "Epoch 114/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0766 - accuracy: 0.9843 - val_loss: 0.1051 - val_accuracy: 0.9628\n",
            "Epoch 115/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0763 - accuracy: 0.9843 - val_loss: 0.1050 - val_accuracy: 0.9628\n",
            "Epoch 116/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0760 - accuracy: 0.9843 - val_loss: 0.1049 - val_accuracy: 0.9628\n",
            "Epoch 117/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0756 - accuracy: 0.9843 - val_loss: 0.1049 - val_accuracy: 0.9628\n",
            "Epoch 118/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0753 - accuracy: 0.9843 - val_loss: 0.1048 - val_accuracy: 0.9628\n",
            "Epoch 119/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0750 - accuracy: 0.9843 - val_loss: 0.1047 - val_accuracy: 0.9628\n",
            "Epoch 120/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0747 - accuracy: 0.9843 - val_loss: 0.1047 - val_accuracy: 0.9628\n",
            "Epoch 121/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0744 - accuracy: 0.9843 - val_loss: 0.1046 - val_accuracy: 0.9628\n",
            "Epoch 122/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0741 - accuracy: 0.9843 - val_loss: 0.1046 - val_accuracy: 0.9628\n",
            "Epoch 123/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0738 - accuracy: 0.9843 - val_loss: 0.1045 - val_accuracy: 0.9628\n",
            "Epoch 124/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0735 - accuracy: 0.9843 - val_loss: 0.1045 - val_accuracy: 0.9628\n",
            "Epoch 125/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0732 - accuracy: 0.9843 - val_loss: 0.1044 - val_accuracy: 0.9628\n",
            "Epoch 126/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0730 - accuracy: 0.9843 - val_loss: 0.1043 - val_accuracy: 0.9628\n",
            "Epoch 127/200\n",
            "381/381 [==============================] - 0s 157us/sample - loss: 0.0727 - accuracy: 0.9843 - val_loss: 0.1044 - val_accuracy: 0.9628\n",
            "Epoch 128/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0724 - accuracy: 0.9843 - val_loss: 0.1044 - val_accuracy: 0.9574\n",
            "Epoch 129/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0721 - accuracy: 0.9843 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 130/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0719 - accuracy: 0.9843 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 131/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0716 - accuracy: 0.9843 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 132/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0713 - accuracy: 0.9843 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 133/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0711 - accuracy: 0.9843 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 134/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0708 - accuracy: 0.9843 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 135/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0706 - accuracy: 0.9843 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 136/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0703 - accuracy: 0.9843 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 137/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0700 - accuracy: 0.9843 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 138/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0698 - accuracy: 0.9843 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
            "Epoch 139/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0696 - accuracy: 0.9869 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 140/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0693 - accuracy: 0.9869 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
            "Epoch 141/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0691 - accuracy: 0.9869 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
            "Epoch 142/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0688 - accuracy: 0.9869 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
            "Epoch 143/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0686 - accuracy: 0.9869 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
            "Epoch 144/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0684 - accuracy: 0.9869 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
            "Epoch 145/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0682 - accuracy: 0.9869 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 146/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0679 - accuracy: 0.9869 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
            "Epoch 147/200\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.0677 - accuracy: 0.9869 - val_loss: 0.1041 - val_accuracy: 0.9574\n",
            "Epoch 148/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0675 - accuracy: 0.9869 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 149/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0673 - accuracy: 0.9869 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 150/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0671 - accuracy: 0.9869 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 151/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0668 - accuracy: 0.9869 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 152/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0666 - accuracy: 0.9869 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 153/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0664 - accuracy: 0.9869 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 154/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0662 - accuracy: 0.9869 - val_loss: 0.1042 - val_accuracy: 0.9574\n",
            "Epoch 155/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0660 - accuracy: 0.9869 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 156/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0658 - accuracy: 0.9869 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 157/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0656 - accuracy: 0.9869 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 158/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0654 - accuracy: 0.9869 - val_loss: 0.1044 - val_accuracy: 0.9574\n",
            "Epoch 159/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0652 - accuracy: 0.9869 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 160/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0650 - accuracy: 0.9869 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 161/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
            "Epoch 162/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0647 - accuracy: 0.9869 - val_loss: 0.1044 - val_accuracy: 0.9574\n",
            "Epoch 163/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0645 - accuracy: 0.9869 - val_loss: 0.1045 - val_accuracy: 0.9574\n",
            "Epoch 164/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0643 - accuracy: 0.9869 - val_loss: 0.1045 - val_accuracy: 0.9574\n",
            "Epoch 165/200\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.0641 - accuracy: 0.9869 - val_loss: 0.1045 - val_accuracy: 0.9574\n",
            "Epoch 166/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0639 - accuracy: 0.9869 - val_loss: 0.1045 - val_accuracy: 0.9574\n",
            "Epoch 167/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0637 - accuracy: 0.9869 - val_loss: 0.1046 - val_accuracy: 0.9574\n",
            "Epoch 168/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.0635 - accuracy: 0.9869 - val_loss: 0.1046 - val_accuracy: 0.9574\n",
            "Epoch 169/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0634 - accuracy: 0.9869 - val_loss: 0.1047 - val_accuracy: 0.9574\n",
            "Epoch 170/200\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.0632 - accuracy: 0.9869 - val_loss: 0.1047 - val_accuracy: 0.9574\n",
            "Epoch 171/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.1047 - val_accuracy: 0.9574\n",
            "Epoch 172/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0628 - accuracy: 0.9869 - val_loss: 0.1047 - val_accuracy: 0.9574\n",
            "Epoch 173/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0627 - accuracy: 0.9869 - val_loss: 0.1048 - val_accuracy: 0.9574\n",
            "Epoch 174/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.1048 - val_accuracy: 0.9574\n",
            "Epoch 175/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0623 - accuracy: 0.9869 - val_loss: 0.1048 - val_accuracy: 0.9574\n",
            "Epoch 176/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.1049 - val_accuracy: 0.9574\n",
            "Epoch 177/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0620 - accuracy: 0.9869 - val_loss: 0.1050 - val_accuracy: 0.9574\n",
            "Epoch 178/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.1049 - val_accuracy: 0.9574\n",
            "Epoch 179/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0617 - accuracy: 0.9869 - val_loss: 0.1050 - val_accuracy: 0.9574\n",
            "Epoch 180/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0615 - accuracy: 0.9869 - val_loss: 0.1051 - val_accuracy: 0.9574\n",
            "Epoch 181/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.1051 - val_accuracy: 0.9574\n",
            "Epoch 182/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0612 - accuracy: 0.9869 - val_loss: 0.1052 - val_accuracy: 0.9574\n",
            "Epoch 183/200\n",
            "381/381 [==============================] - 0s 174us/sample - loss: 0.0610 - accuracy: 0.9869 - val_loss: 0.1052 - val_accuracy: 0.9574\n",
            "Epoch 184/200\n",
            "381/381 [==============================] - 0s 154us/sample - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.1052 - val_accuracy: 0.9574\n",
            "Epoch 185/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.1053 - val_accuracy: 0.9574\n",
            "Epoch 186/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0606 - accuracy: 0.9869 - val_loss: 0.1054 - val_accuracy: 0.9574\n",
            "Epoch 187/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0604 - accuracy: 0.9869 - val_loss: 0.1054 - val_accuracy: 0.9574\n",
            "Epoch 188/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.1055 - val_accuracy: 0.9574\n",
            "Epoch 189/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0601 - accuracy: 0.9869 - val_loss: 0.1055 - val_accuracy: 0.9574\n",
            "Epoch 190/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0600 - accuracy: 0.9869 - val_loss: 0.1055 - val_accuracy: 0.9574\n",
            "Epoch 191/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0598 - accuracy: 0.9869 - val_loss: 0.1056 - val_accuracy: 0.9574\n",
            "Epoch 192/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.1056 - val_accuracy: 0.9574\n",
            "Epoch 193/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0596 - accuracy: 0.9869 - val_loss: 0.1056 - val_accuracy: 0.9574\n",
            "Epoch 194/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.1057 - val_accuracy: 0.9574\n",
            "Epoch 195/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.1058 - val_accuracy: 0.9574\n",
            "Epoch 196/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.1058 - val_accuracy: 0.9574\n",
            "Epoch 197/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0590 - accuracy: 0.9869 - val_loss: 0.1059 - val_accuracy: 0.9574\n",
            "Epoch 198/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.1060 - val_accuracy: 0.9574\n",
            "Epoch 199/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0588 - accuracy: 0.9869 - val_loss: 0.1061 - val_accuracy: 0.9574\n",
            "Epoch 200/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0586 - accuracy: 0.9869 - val_loss: 0.1060 - val_accuracy: 0.9574\n",
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/200\n",
            "381/381 [==============================] - 0s 832us/sample - loss: 1.2016 - accuracy: 0.1969 - val_loss: 1.1398 - val_accuracy: 0.2500\n",
            "Epoch 2/200\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 1.0969 - accuracy: 0.2388 - val_loss: 1.0338 - val_accuracy: 0.2872\n",
            "Epoch 3/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.9959 - accuracy: 0.2887 - val_loss: 0.9412 - val_accuracy: 0.3404\n",
            "Epoch 4/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.9106 - accuracy: 0.3412 - val_loss: 0.8575 - val_accuracy: 0.4202\n",
            "Epoch 5/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.8333 - accuracy: 0.4042 - val_loss: 0.7847 - val_accuracy: 0.4681\n",
            "Epoch 6/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.7657 - accuracy: 0.4724 - val_loss: 0.7218 - val_accuracy: 0.5426\n",
            "Epoch 7/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.7067 - accuracy: 0.5827 - val_loss: 0.6675 - val_accuracy: 0.6011\n",
            "Epoch 8/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.6551 - accuracy: 0.6483 - val_loss: 0.6203 - val_accuracy: 0.6596\n",
            "Epoch 9/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.6104 - accuracy: 0.7034 - val_loss: 0.5794 - val_accuracy: 0.7021\n",
            "Epoch 10/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.5719 - accuracy: 0.7559 - val_loss: 0.5431 - val_accuracy: 0.7606\n",
            "Epoch 11/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.5376 - accuracy: 0.7927 - val_loss: 0.5112 - val_accuracy: 0.7872\n",
            "Epoch 12/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.5075 - accuracy: 0.8215 - val_loss: 0.4834 - val_accuracy: 0.8085\n",
            "Epoch 13/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.4810 - accuracy: 0.8346 - val_loss: 0.4589 - val_accuracy: 0.8191\n",
            "Epoch 14/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.4568 - accuracy: 0.8399 - val_loss: 0.4370 - val_accuracy: 0.8298\n",
            "Epoch 15/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.4359 - accuracy: 0.8583 - val_loss: 0.4172 - val_accuracy: 0.8404\n",
            "Epoch 16/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.4165 - accuracy: 0.8740 - val_loss: 0.3996 - val_accuracy: 0.8511\n",
            "Epoch 17/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.3996 - accuracy: 0.8819 - val_loss: 0.3835 - val_accuracy: 0.8564\n",
            "Epoch 18/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.3840 - accuracy: 0.8819 - val_loss: 0.3687 - val_accuracy: 0.8617\n",
            "Epoch 19/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.3693 - accuracy: 0.8871 - val_loss: 0.3557 - val_accuracy: 0.8777\n",
            "Epoch 20/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.3565 - accuracy: 0.8976 - val_loss: 0.3435 - val_accuracy: 0.8777\n",
            "Epoch 21/200\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.3444 - accuracy: 0.8976 - val_loss: 0.3323 - val_accuracy: 0.8777\n",
            "Epoch 22/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.3331 - accuracy: 0.9003 - val_loss: 0.3222 - val_accuracy: 0.8777\n",
            "Epoch 23/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.3230 - accuracy: 0.9029 - val_loss: 0.3125 - val_accuracy: 0.8830\n",
            "Epoch 24/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.3132 - accuracy: 0.9134 - val_loss: 0.3036 - val_accuracy: 0.8936\n",
            "Epoch 25/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.3043 - accuracy: 0.9160 - val_loss: 0.2952 - val_accuracy: 0.8936\n",
            "Epoch 26/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.2957 - accuracy: 0.9160 - val_loss: 0.2877 - val_accuracy: 0.9043\n",
            "Epoch 27/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.2880 - accuracy: 0.9186 - val_loss: 0.2804 - val_accuracy: 0.9096\n",
            "Epoch 28/200\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.2805 - accuracy: 0.9186 - val_loss: 0.2737 - val_accuracy: 0.9096\n",
            "Epoch 29/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.2736 - accuracy: 0.9213 - val_loss: 0.2672 - val_accuracy: 0.9149\n",
            "Epoch 30/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.2669 - accuracy: 0.9239 - val_loss: 0.2612 - val_accuracy: 0.9149\n",
            "Epoch 31/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.2606 - accuracy: 0.9265 - val_loss: 0.2555 - val_accuracy: 0.9202\n",
            "Epoch 32/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.2547 - accuracy: 0.9318 - val_loss: 0.2501 - val_accuracy: 0.9202\n",
            "Epoch 33/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.2489 - accuracy: 0.9344 - val_loss: 0.2451 - val_accuracy: 0.9202\n",
            "Epoch 34/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.2435 - accuracy: 0.9396 - val_loss: 0.2405 - val_accuracy: 0.9202\n",
            "Epoch 35/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.2385 - accuracy: 0.9396 - val_loss: 0.2358 - val_accuracy: 0.9202\n",
            "Epoch 36/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.2334 - accuracy: 0.9396 - val_loss: 0.2316 - val_accuracy: 0.9202\n",
            "Epoch 37/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.2289 - accuracy: 0.9423 - val_loss: 0.2273 - val_accuracy: 0.9202\n",
            "Epoch 38/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.2243 - accuracy: 0.9423 - val_loss: 0.2234 - val_accuracy: 0.9202\n",
            "Epoch 39/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.2200 - accuracy: 0.9423 - val_loss: 0.2197 - val_accuracy: 0.9255\n",
            "Epoch 40/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.2159 - accuracy: 0.9423 - val_loss: 0.2160 - val_accuracy: 0.9309\n",
            "Epoch 41/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.2119 - accuracy: 0.9449 - val_loss: 0.2124 - val_accuracy: 0.9309\n",
            "Epoch 42/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.2080 - accuracy: 0.9475 - val_loss: 0.2091 - val_accuracy: 0.9309\n",
            "Epoch 43/200\n",
            "381/381 [==============================] - 0s 158us/sample - loss: 0.2043 - accuracy: 0.9475 - val_loss: 0.2061 - val_accuracy: 0.9362\n",
            "Epoch 44/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.2009 - accuracy: 0.9475 - val_loss: 0.2029 - val_accuracy: 0.9362\n",
            "Epoch 45/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1973 - accuracy: 0.9501 - val_loss: 0.2000 - val_accuracy: 0.9362\n",
            "Epoch 46/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1940 - accuracy: 0.9501 - val_loss: 0.1973 - val_accuracy: 0.9362\n",
            "Epoch 47/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1908 - accuracy: 0.9528 - val_loss: 0.1948 - val_accuracy: 0.9362\n",
            "Epoch 48/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1879 - accuracy: 0.9528 - val_loss: 0.1922 - val_accuracy: 0.9362\n",
            "Epoch 49/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1848 - accuracy: 0.9528 - val_loss: 0.1898 - val_accuracy: 0.9362\n",
            "Epoch 50/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1820 - accuracy: 0.9528 - val_loss: 0.1872 - val_accuracy: 0.9362\n",
            "Epoch 51/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.1791 - accuracy: 0.9528 - val_loss: 0.1849 - val_accuracy: 0.9362\n",
            "Epoch 52/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1764 - accuracy: 0.9528 - val_loss: 0.1827 - val_accuracy: 0.9362\n",
            "Epoch 53/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1740 - accuracy: 0.9528 - val_loss: 0.1804 - val_accuracy: 0.9362\n",
            "Epoch 54/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.1712 - accuracy: 0.9528 - val_loss: 0.1783 - val_accuracy: 0.9362\n",
            "Epoch 55/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1688 - accuracy: 0.9554 - val_loss: 0.1763 - val_accuracy: 0.9362\n",
            "Epoch 56/200\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.1664 - accuracy: 0.9580 - val_loss: 0.1743 - val_accuracy: 0.9362\n",
            "Epoch 57/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1643 - accuracy: 0.9580 - val_loss: 0.1724 - val_accuracy: 0.9362\n",
            "Epoch 58/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1618 - accuracy: 0.9580 - val_loss: 0.1707 - val_accuracy: 0.9362\n",
            "Epoch 59/200\n",
            "381/381 [==============================] - 0s 158us/sample - loss: 0.1596 - accuracy: 0.9580 - val_loss: 0.1691 - val_accuracy: 0.9362\n",
            "Epoch 60/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1577 - accuracy: 0.9580 - val_loss: 0.1672 - val_accuracy: 0.9362\n",
            "Epoch 61/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1554 - accuracy: 0.9606 - val_loss: 0.1657 - val_accuracy: 0.9362\n",
            "Epoch 62/200\n",
            "381/381 [==============================] - 0s 159us/sample - loss: 0.1536 - accuracy: 0.9606 - val_loss: 0.1640 - val_accuracy: 0.9362\n",
            "Epoch 63/200\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.1516 - accuracy: 0.9606 - val_loss: 0.1625 - val_accuracy: 0.9362\n",
            "Epoch 64/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1497 - accuracy: 0.9633 - val_loss: 0.1611 - val_accuracy: 0.9362\n",
            "Epoch 65/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1478 - accuracy: 0.9633 - val_loss: 0.1597 - val_accuracy: 0.9362\n",
            "Epoch 66/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1460 - accuracy: 0.9633 - val_loss: 0.1583 - val_accuracy: 0.9362\n",
            "Epoch 67/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1443 - accuracy: 0.9633 - val_loss: 0.1570 - val_accuracy: 0.9362\n",
            "Epoch 68/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.1428 - accuracy: 0.9633 - val_loss: 0.1556 - val_accuracy: 0.9362\n",
            "Epoch 69/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.1410 - accuracy: 0.9633 - val_loss: 0.1544 - val_accuracy: 0.9362\n",
            "Epoch 70/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1394 - accuracy: 0.9633 - val_loss: 0.1531 - val_accuracy: 0.9362\n",
            "Epoch 71/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1378 - accuracy: 0.9633 - val_loss: 0.1520 - val_accuracy: 0.9362\n",
            "Epoch 72/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1363 - accuracy: 0.9633 - val_loss: 0.1508 - val_accuracy: 0.9362\n",
            "Epoch 73/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1348 - accuracy: 0.9659 - val_loss: 0.1498 - val_accuracy: 0.9362\n",
            "Epoch 74/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1335 - accuracy: 0.9659 - val_loss: 0.1487 - val_accuracy: 0.9362\n",
            "Epoch 75/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.1321 - accuracy: 0.9659 - val_loss: 0.1476 - val_accuracy: 0.9362\n",
            "Epoch 76/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1307 - accuracy: 0.9659 - val_loss: 0.1467 - val_accuracy: 0.9362\n",
            "Epoch 77/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1294 - accuracy: 0.9659 - val_loss: 0.1457 - val_accuracy: 0.9362\n",
            "Epoch 78/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1281 - accuracy: 0.9659 - val_loss: 0.1447 - val_accuracy: 0.9362\n",
            "Epoch 79/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1268 - accuracy: 0.9685 - val_loss: 0.1438 - val_accuracy: 0.9362\n",
            "Epoch 80/200\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.1256 - accuracy: 0.9685 - val_loss: 0.1429 - val_accuracy: 0.9362\n",
            "Epoch 81/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.1244 - accuracy: 0.9685 - val_loss: 0.1420 - val_accuracy: 0.9468\n",
            "Epoch 82/200\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.1233 - accuracy: 0.9685 - val_loss: 0.1411 - val_accuracy: 0.9521\n",
            "Epoch 83/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1221 - accuracy: 0.9711 - val_loss: 0.1403 - val_accuracy: 0.9521\n",
            "Epoch 84/200\n",
            "381/381 [==============================] - 0s 176us/sample - loss: 0.1210 - accuracy: 0.9711 - val_loss: 0.1395 - val_accuracy: 0.9521\n",
            "Epoch 85/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1200 - accuracy: 0.9711 - val_loss: 0.1387 - val_accuracy: 0.9521\n",
            "Epoch 86/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.1189 - accuracy: 0.9711 - val_loss: 0.1379 - val_accuracy: 0.9521\n",
            "Epoch 87/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1179 - accuracy: 0.9711 - val_loss: 0.1372 - val_accuracy: 0.9574\n",
            "Epoch 88/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1169 - accuracy: 0.9738 - val_loss: 0.1365 - val_accuracy: 0.9574\n",
            "Epoch 89/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1160 - accuracy: 0.9738 - val_loss: 0.1358 - val_accuracy: 0.9574\n",
            "Epoch 90/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1151 - accuracy: 0.9738 - val_loss: 0.1351 - val_accuracy: 0.9574\n",
            "Epoch 91/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1141 - accuracy: 0.9738 - val_loss: 0.1344 - val_accuracy: 0.9574\n",
            "Epoch 92/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1132 - accuracy: 0.9738 - val_loss: 0.1338 - val_accuracy: 0.9574\n",
            "Epoch 93/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.1123 - accuracy: 0.9738 - val_loss: 0.1332 - val_accuracy: 0.9574\n",
            "Epoch 94/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1114 - accuracy: 0.9738 - val_loss: 0.1326 - val_accuracy: 0.9574\n",
            "Epoch 95/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1106 - accuracy: 0.9764 - val_loss: 0.1319 - val_accuracy: 0.9574\n",
            "Epoch 96/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1098 - accuracy: 0.9764 - val_loss: 0.1314 - val_accuracy: 0.9574\n",
            "Epoch 97/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1090 - accuracy: 0.9764 - val_loss: 0.1308 - val_accuracy: 0.9574\n",
            "Epoch 98/200\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.1082 - accuracy: 0.9764 - val_loss: 0.1303 - val_accuracy: 0.9574\n",
            "Epoch 99/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.1074 - accuracy: 0.9790 - val_loss: 0.1297 - val_accuracy: 0.9574\n",
            "Epoch 100/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.1067 - accuracy: 0.9790 - val_loss: 0.1291 - val_accuracy: 0.9574\n",
            "Epoch 101/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1059 - accuracy: 0.9790 - val_loss: 0.1286 - val_accuracy: 0.9574\n",
            "Epoch 102/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.1052 - accuracy: 0.9816 - val_loss: 0.1281 - val_accuracy: 0.9574\n",
            "Epoch 103/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1045 - accuracy: 0.9816 - val_loss: 0.1275 - val_accuracy: 0.9574\n",
            "Epoch 104/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1038 - accuracy: 0.9816 - val_loss: 0.1271 - val_accuracy: 0.9574\n",
            "Epoch 105/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1031 - accuracy: 0.9816 - val_loss: 0.1266 - val_accuracy: 0.9574\n",
            "Epoch 106/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1025 - accuracy: 0.9816 - val_loss: 0.1262 - val_accuracy: 0.9574\n",
            "Epoch 107/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1018 - accuracy: 0.9816 - val_loss: 0.1257 - val_accuracy: 0.9574\n",
            "Epoch 108/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1012 - accuracy: 0.9816 - val_loss: 0.1253 - val_accuracy: 0.9574\n",
            "Epoch 109/200\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.1005 - accuracy: 0.9816 - val_loss: 0.1248 - val_accuracy: 0.9574\n",
            "Epoch 110/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0999 - accuracy: 0.9816 - val_loss: 0.1243 - val_accuracy: 0.9574\n",
            "Epoch 111/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0993 - accuracy: 0.9816 - val_loss: 0.1240 - val_accuracy: 0.9574\n",
            "Epoch 112/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0987 - accuracy: 0.9816 - val_loss: 0.1236 - val_accuracy: 0.9574\n",
            "Epoch 113/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0981 - accuracy: 0.9843 - val_loss: 0.1232 - val_accuracy: 0.9574\n",
            "Epoch 114/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0976 - accuracy: 0.9843 - val_loss: 0.1227 - val_accuracy: 0.9574\n",
            "Epoch 115/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0970 - accuracy: 0.9843 - val_loss: 0.1223 - val_accuracy: 0.9574\n",
            "Epoch 116/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0964 - accuracy: 0.9816 - val_loss: 0.1220 - val_accuracy: 0.9574\n",
            "Epoch 117/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0959 - accuracy: 0.9816 - val_loss: 0.1216 - val_accuracy: 0.9574\n",
            "Epoch 118/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0954 - accuracy: 0.9816 - val_loss: 0.1213 - val_accuracy: 0.9574\n",
            "Epoch 119/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0949 - accuracy: 0.9816 - val_loss: 0.1209 - val_accuracy: 0.9574\n",
            "Epoch 120/200\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0943 - accuracy: 0.9816 - val_loss: 0.1205 - val_accuracy: 0.9574\n",
            "Epoch 121/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0939 - accuracy: 0.9816 - val_loss: 0.1201 - val_accuracy: 0.9574\n",
            "Epoch 122/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0933 - accuracy: 0.9816 - val_loss: 0.1198 - val_accuracy: 0.9574\n",
            "Epoch 123/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0928 - accuracy: 0.9816 - val_loss: 0.1195 - val_accuracy: 0.9574\n",
            "Epoch 124/200\n",
            "381/381 [==============================] - 0s 148us/sample - loss: 0.0924 - accuracy: 0.9816 - val_loss: 0.1192 - val_accuracy: 0.9574\n",
            "Epoch 125/200\n",
            "381/381 [==============================] - 0s 159us/sample - loss: 0.0919 - accuracy: 0.9816 - val_loss: 0.1188 - val_accuracy: 0.9574\n",
            "Epoch 126/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0914 - accuracy: 0.9816 - val_loss: 0.1185 - val_accuracy: 0.9574\n",
            "Epoch 127/200\n",
            "381/381 [==============================] - 0s 151us/sample - loss: 0.0910 - accuracy: 0.9816 - val_loss: 0.1182 - val_accuracy: 0.9574\n",
            "Epoch 128/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0905 - accuracy: 0.9816 - val_loss: 0.1179 - val_accuracy: 0.9574\n",
            "Epoch 129/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0901 - accuracy: 0.9816 - val_loss: 0.1176 - val_accuracy: 0.9574\n",
            "Epoch 130/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.0896 - accuracy: 0.9816 - val_loss: 0.1173 - val_accuracy: 0.9574\n",
            "Epoch 131/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0892 - accuracy: 0.9843 - val_loss: 0.1170 - val_accuracy: 0.9574\n",
            "Epoch 132/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0888 - accuracy: 0.9843 - val_loss: 0.1168 - val_accuracy: 0.9574\n",
            "Epoch 133/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0884 - accuracy: 0.9843 - val_loss: 0.1165 - val_accuracy: 0.9574\n",
            "Epoch 134/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0879 - accuracy: 0.9843 - val_loss: 0.1162 - val_accuracy: 0.9574\n",
            "Epoch 135/200\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.0875 - accuracy: 0.9843 - val_loss: 0.1159 - val_accuracy: 0.9574\n",
            "Epoch 136/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0871 - accuracy: 0.9843 - val_loss: 0.1157 - val_accuracy: 0.9574\n",
            "Epoch 137/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0868 - accuracy: 0.9843 - val_loss: 0.1154 - val_accuracy: 0.9574\n",
            "Epoch 138/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0863 - accuracy: 0.9843 - val_loss: 0.1152 - val_accuracy: 0.9574\n",
            "Epoch 139/200\n",
            "381/381 [==============================] - 0s 162us/sample - loss: 0.0860 - accuracy: 0.9843 - val_loss: 0.1150 - val_accuracy: 0.9574\n",
            "Epoch 140/200\n",
            "381/381 [==============================] - 0s 181us/sample - loss: 0.0856 - accuracy: 0.9843 - val_loss: 0.1147 - val_accuracy: 0.9574\n",
            "Epoch 141/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0852 - accuracy: 0.9843 - val_loss: 0.1144 - val_accuracy: 0.9574\n",
            "Epoch 142/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0849 - accuracy: 0.9843 - val_loss: 0.1142 - val_accuracy: 0.9574\n",
            "Epoch 143/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.0845 - accuracy: 0.9843 - val_loss: 0.1140 - val_accuracy: 0.9574\n",
            "Epoch 144/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0841 - accuracy: 0.9843 - val_loss: 0.1138 - val_accuracy: 0.9574\n",
            "Epoch 145/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0838 - accuracy: 0.9843 - val_loss: 0.1135 - val_accuracy: 0.9574\n",
            "Epoch 146/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0834 - accuracy: 0.9843 - val_loss: 0.1133 - val_accuracy: 0.9574\n",
            "Epoch 147/200\n",
            "381/381 [==============================] - 0s 153us/sample - loss: 0.0831 - accuracy: 0.9843 - val_loss: 0.1131 - val_accuracy: 0.9574\n",
            "Epoch 148/200\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.0828 - accuracy: 0.9843 - val_loss: 0.1129 - val_accuracy: 0.9574\n",
            "Epoch 149/200\n",
            "381/381 [==============================] - 0s 160us/sample - loss: 0.0824 - accuracy: 0.9843 - val_loss: 0.1127 - val_accuracy: 0.9574\n",
            "Epoch 150/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0821 - accuracy: 0.9843 - val_loss: 0.1125 - val_accuracy: 0.9574\n",
            "Epoch 151/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0817 - accuracy: 0.9843 - val_loss: 0.1122 - val_accuracy: 0.9574\n",
            "Epoch 152/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0814 - accuracy: 0.9843 - val_loss: 0.1121 - val_accuracy: 0.9574\n",
            "Epoch 153/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.0811 - accuracy: 0.9843 - val_loss: 0.1119 - val_accuracy: 0.9574\n",
            "Epoch 154/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0808 - accuracy: 0.9843 - val_loss: 0.1117 - val_accuracy: 0.9574\n",
            "Epoch 155/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0805 - accuracy: 0.9843 - val_loss: 0.1115 - val_accuracy: 0.9574\n",
            "Epoch 156/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0802 - accuracy: 0.9843 - val_loss: 0.1113 - val_accuracy: 0.9574\n",
            "Epoch 157/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0799 - accuracy: 0.9843 - val_loss: 0.1111 - val_accuracy: 0.9574\n",
            "Epoch 158/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0796 - accuracy: 0.9843 - val_loss: 0.1110 - val_accuracy: 0.9574\n",
            "Epoch 159/200\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.0793 - accuracy: 0.9843 - val_loss: 0.1108 - val_accuracy: 0.9574\n",
            "Epoch 160/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0790 - accuracy: 0.9843 - val_loss: 0.1107 - val_accuracy: 0.9574\n",
            "Epoch 161/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0787 - accuracy: 0.9869 - val_loss: 0.1105 - val_accuracy: 0.9574\n",
            "Epoch 162/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0784 - accuracy: 0.9869 - val_loss: 0.1103 - val_accuracy: 0.9574\n",
            "Epoch 163/200\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.0781 - accuracy: 0.9869 - val_loss: 0.1101 - val_accuracy: 0.9574\n",
            "Epoch 164/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0779 - accuracy: 0.9869 - val_loss: 0.1100 - val_accuracy: 0.9574\n",
            "Epoch 165/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0776 - accuracy: 0.9869 - val_loss: 0.1098 - val_accuracy: 0.9574\n",
            "Epoch 166/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0773 - accuracy: 0.9869 - val_loss: 0.1097 - val_accuracy: 0.9574\n",
            "Epoch 167/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0771 - accuracy: 0.9869 - val_loss: 0.1096 - val_accuracy: 0.9574\n",
            "Epoch 168/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0768 - accuracy: 0.9869 - val_loss: 0.1094 - val_accuracy: 0.9574\n",
            "Epoch 169/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0765 - accuracy: 0.9869 - val_loss: 0.1092 - val_accuracy: 0.9574\n",
            "Epoch 170/200\n",
            "381/381 [==============================] - 0s 181us/sample - loss: 0.0763 - accuracy: 0.9869 - val_loss: 0.1091 - val_accuracy: 0.9574\n",
            "Epoch 171/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0760 - accuracy: 0.9869 - val_loss: 0.1090 - val_accuracy: 0.9574\n",
            "Epoch 172/200\n",
            "381/381 [==============================] - 0s 148us/sample - loss: 0.0757 - accuracy: 0.9869 - val_loss: 0.1089 - val_accuracy: 0.9574\n",
            "Epoch 173/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0755 - accuracy: 0.9869 - val_loss: 0.1086 - val_accuracy: 0.9574\n",
            "Epoch 174/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0752 - accuracy: 0.9869 - val_loss: 0.1085 - val_accuracy: 0.9574\n",
            "Epoch 175/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0750 - accuracy: 0.9869 - val_loss: 0.1084 - val_accuracy: 0.9574\n",
            "Epoch 176/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0747 - accuracy: 0.9869 - val_loss: 0.1083 - val_accuracy: 0.9574\n",
            "Epoch 177/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0745 - accuracy: 0.9869 - val_loss: 0.1082 - val_accuracy: 0.9574\n",
            "Epoch 178/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0742 - accuracy: 0.9869 - val_loss: 0.1081 - val_accuracy: 0.9574\n",
            "Epoch 179/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0740 - accuracy: 0.9869 - val_loss: 0.1080 - val_accuracy: 0.9574\n",
            "Epoch 180/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0738 - accuracy: 0.9869 - val_loss: 0.1078 - val_accuracy: 0.9574\n",
            "Epoch 181/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0735 - accuracy: 0.9869 - val_loss: 0.1077 - val_accuracy: 0.9574\n",
            "Epoch 182/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0733 - accuracy: 0.9869 - val_loss: 0.1076 - val_accuracy: 0.9574\n",
            "Epoch 183/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0731 - accuracy: 0.9869 - val_loss: 0.1075 - val_accuracy: 0.9574\n",
            "Epoch 184/200\n",
            "381/381 [==============================] - 0s 164us/sample - loss: 0.0729 - accuracy: 0.9869 - val_loss: 0.1073 - val_accuracy: 0.9574\n",
            "Epoch 185/200\n",
            "381/381 [==============================] - 0s 159us/sample - loss: 0.0727 - accuracy: 0.9869 - val_loss: 0.1072 - val_accuracy: 0.9574\n",
            "Epoch 186/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0724 - accuracy: 0.9869 - val_loss: 0.1072 - val_accuracy: 0.9574\n",
            "Epoch 187/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0722 - accuracy: 0.9869 - val_loss: 0.1071 - val_accuracy: 0.9574\n",
            "Epoch 188/200\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0720 - accuracy: 0.9869 - val_loss: 0.1069 - val_accuracy: 0.9574\n",
            "Epoch 189/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.0718 - accuracy: 0.9869 - val_loss: 0.1068 - val_accuracy: 0.9574\n",
            "Epoch 190/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0715 - accuracy: 0.9869 - val_loss: 0.1067 - val_accuracy: 0.9574\n",
            "Epoch 191/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0713 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9574\n",
            "Epoch 192/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0711 - accuracy: 0.9869 - val_loss: 0.1066 - val_accuracy: 0.9574\n",
            "Epoch 193/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0709 - accuracy: 0.9869 - val_loss: 0.1065 - val_accuracy: 0.9574\n",
            "Epoch 194/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0707 - accuracy: 0.9869 - val_loss: 0.1064 - val_accuracy: 0.9574\n",
            "Epoch 195/200\n",
            "381/381 [==============================] - 0s 159us/sample - loss: 0.0705 - accuracy: 0.9869 - val_loss: 0.1063 - val_accuracy: 0.9574\n",
            "Epoch 196/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0703 - accuracy: 0.9869 - val_loss: 0.1062 - val_accuracy: 0.9574\n",
            "Epoch 197/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0701 - accuracy: 0.9869 - val_loss: 0.1062 - val_accuracy: 0.9574\n",
            "Epoch 198/200\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.0699 - accuracy: 0.9869 - val_loss: 0.1060 - val_accuracy: 0.9574\n",
            "Epoch 199/200\n",
            "381/381 [==============================] - 0s 148us/sample - loss: 0.0697 - accuracy: 0.9869 - val_loss: 0.1060 - val_accuracy: 0.9574\n",
            "Epoch 200/200\n",
            "381/381 [==============================] - 0s 166us/sample - loss: 0.0695 - accuracy: 0.9869 - val_loss: 0.1059 - val_accuracy: 0.9574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaACKIgY93Ya",
        "colab_type": "code",
        "outputId": "ccc3cded-c767-4519-a047-ff0005649bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# We now evaluate the model\n",
        "\n",
        "print(\"Model1:\")\n",
        "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
        "print(\"Test score:\", model.evaluate(X_test, y_test))\n",
        "\n",
        "print(\"Model2:\")\n",
        "print(\"Train score:\", model2.evaluate(X_train, y_train))\n",
        "print(\"Test score:\", model2.evaluate(X_test, y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model1:\n",
            "381/381 [==============================] - 0s 60us/sample - loss: 0.0585 - accuracy: 0.9869\n",
            "Train score: [0.058514195032359106, 0.98687667]\n",
            "188/188 [==============================] - 0s 80us/sample - loss: 0.1060 - accuracy: 0.9574\n",
            "Test score: [0.10599766322906981, 0.9574468]\n",
            "Model2:\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.0694 - accuracy: 0.9869\n",
            "Train score: [0.06938496323942825, 0.98687667]\n",
            "188/188 [==============================] - 0s 85us/sample - loss: 0.1059 - accuracy: 0.9574\n",
            "Test score: [0.10590110846022342, 0.9574468]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pyU8jRx-L8L",
        "colab_type": "code",
        "outputId": "5be6a7a6-4fc3-41cb-a255-50c299263674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# The obtained accuracty is about 97% on both the train and test sets, for both models.\n",
        "# We now plot what has been returned by the fit function, as weel as the accuracy.\n",
        "\n",
        "# Plot what's returned by model.fit()\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.title(\"Model1\")\n",
        "plt.legend()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcde01842b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clFkOabM-rVz",
        "colab_type": "code",
        "outputId": "543e0a27-9dcc-4ecc-d9ef-a7cdc43a306a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.plot(r2.history['loss'], label='loss')\n",
        "plt.plot(r2.history['val_loss'], label='val_loss')\n",
        "plt.title(\"Model2\")\n",
        "plt.legend()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcde02206d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMeCHj2k-w9Z",
        "colab_type": "code",
        "outputId": "fa29fc30-0ee4-48e5-ae6d-67a1af841ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Plot the accuracy too\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcde011bf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mUiSSCq-7Ce",
        "colab_type": "code",
        "outputId": "0871cbb6-73a9-4eb8-b3ba-6336f5b9ee15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "\n",
        "plt.plot(r2.history['accuracy'], label='acc')\n",
        "plt.plot(r2.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcde0085a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAl1EJEUo0EVEUsT/ByMSOkNKKZtSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th7Ct7-fTqnP",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 - Making Predictions\n",
        "\n",
        "This code looks at how the previously trained models can be used in order to generate predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jjZsDr-Tyd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We first want to make a prediction. These values are probabilities\n",
        "Predicted = model2.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSvqYPjRUUaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To get actual classes, the Prediction values need to be rounded.\n",
        "# The predicted values also need to be flatten, to match the target size (N,)\n",
        "\n",
        "Predicted = np.round(Predicted).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8qzV8hIUVoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8eb414e5-bb85-4906-b97d-cdcf4fe1b711"
      },
      "source": [
        "# Finally, we calculate the accuracy, both manually and using the evaluate function.\n",
        "print(\"Manual calculation:\", np.mean(Predicted==y_test))\n",
        "print(\"Evaluate calculation:\", model2.evaluate(X_test, y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manual calculation: 0.9574468085106383\n",
            "188/188 [==============================] - 0s 86us/sample - loss: 0.1059 - accuracy: 0.9574\n",
            "Evaluate calculation: [0.10590110846022342, 0.9574468]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESzuZRxWS3L",
        "colab_type": "text"
      },
      "source": [
        "# Part 3 - Making Predictions\n",
        "\n",
        "This code looks at how the above model can be saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc_Dx2tzWQUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save('linear_classification.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xd6uauEXROE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "29d671d4-dd66-4d73-f05e-216a22501318"
      },
      "source": [
        "# Confirming file stored locally.\n",
        "!ls -lh"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 24K\n",
            "-rw-r--r-- 1 root root  19K Feb 10 18:29 linear_classification.h5\n",
            "drwxr-xr-x 1 root root 4.0K Feb  5 18:37 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLbMYinwXUfv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2c8d8df1-fae8-4a86-dadf-838779ffb8c6"
      },
      "source": [
        "# Let's load the model and confirm that it still works\n",
        "# Note: there is a bug in Keras where load/save only works if you DON'T use the Input() layer explicitly\n",
        "# So, make sure you define the model with ONLY Dense(1, input_shape=(D,))\n",
        "# At least, until the bug is fixed\n",
        "# https://github.com/keras-team/keras/issues/10417\n",
        "\n",
        "model = tf.keras.models.load_model('linear_classification.h5')\n",
        "print(model.layers)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.layers.core.Dense object at 0x7fcde03aacf8>]\n",
            "188/188 [==============================] - 0s 423us/sample - loss: 0.1059 - accuracy: 0.9574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10590110846022342, 0.9574468]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0sUcK1bXX1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the file - requires Chrome (at this point)\n",
        "from google.colab import files\n",
        "files.download('linear_classification.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT_2rqs3Xf0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}