# -*- coding: utf-8 -*-
"""Linear Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lB6DINr3vyoFDr9XSVzSOkJRilvHGh2w

# Part 1 - Model Training

This code looks at creating a linear classification algorithm, assessing if a tumor is malignent or benign.
"""

# Commented out IPython magic to ensure Python compatibility.
# We first verify the correct version of TF installed
# !pip install -q tensorflow-gpu==2.1.0

try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
print(tf.__version__)
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import numpy as np

# Next, we load the data
data = load_breast_cancer()
print("Data Type:", type(data))
# The data is a Bunch objsect, meaning it is a dictionary, where the keys can be treated as atribus

data.keys()

data.data.shape # the data.data reffers to the input data

data.target.shape # the data.target reffers to the target/output data, a 1D array of 0s and 1s

# These ar ethe names of the various inputs and feature
print(data.target_names)
print(data.feature_names)

# We split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)

# We scale the data, to make sure the ranges/scales of all the inputs are similar.
# We substract the mean and divide by the standard deviation

X_train = StandardScaler().fit_transform(X_train)
X_test = StandardScaler().fit_transform(X_test)

N,D = X_train.shape

# This is where the model is created
# First, a model object is created. This is a Sequential-type object. 
# The object takes an input, which specifies the shape of the Input, while the Dense takes the input and does a linear transformation to get an output of sieze 1.

model = tf.keras.models.Sequential(
    [
     tf.keras.layers.Input(shape=(D,)),
     tf.keras.layers.Dense(1, activation='sigmoid')
    ]
)

# Alternativelly, we can also define the model (model2) as follows. This allows us to add layers.

model2 = tf.keras.models.Sequential()
model2.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))

# The next step is to compile the models.

model.compile(
    optimizer = 'adam',
    loss = 'binary_crossentropy',
    metrics = ['accuracy']
)

model2.compile(
    optimizer = 'adam',
    loss = 'binary_crossentropy',
    metrics = ['accuracy']
)

# Then, we train the two models

r = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 200)
r2 = model2.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 200)

# We now evaluate the model

print("Model1:")
print("Train score:", model.evaluate(X_train, y_train))
print("Test score:", model.evaluate(X_test, y_test))

print("Model2:")
print("Train score:", model2.evaluate(X_train, y_train))
print("Test score:", model2.evaluate(X_test, y_test))

# The obtained accuracty is about 97% on both the train and test sets, for both models.
# We now plot what has been returned by the fit function, as weel as the accuracy.

# Plot what's returned by model.fit()
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')
plt.title("Model1")
plt.legend()

plt.plot(r2.history['loss'], label='loss')
plt.plot(r2.history['val_loss'], label='val_loss')
plt.title("Model2")
plt.legend()

# Plot the accuracy too
plt.plot(r.history['accuracy'], label='acc')
plt.plot(r.history['val_accuracy'], label='val_acc')
plt.legend()

plt.plot(r2.history['accuracy'], label='acc')
plt.plot(r2.history['val_accuracy'], label='val_acc')
plt.legend()

"""# Part 2 - Making Predictions

This code looks at how the previously trained models can be used in order to generate predictions
"""

# We first want to make a prediction. These values are probabilities
Predicted = model2.predict(X_test)

# To get actual classes, the Prediction values need to be rounded.
# The predicted values also need to be flatten, to match the target size (N,)

Predicted = np.round(Predicted).flatten()

# Finally, we calculate the accuracy, both manually and using the evaluate function.
print("Manual calculation:", np.mean(Predicted==y_test))
print("Evaluate calculation:", model2.evaluate(X_test, y_test))

"""# Part 3 - Making Predictions

This code looks at how the above model can be saved.
"""

model2.save('linear_classification.h5')

# Confirming file stored locally.
!ls -lh

# Let's load the model and confirm that it still works
# Note: there is a bug in Keras where load/save only works if you DON'T use the Input() layer explicitly
# So, make sure you define the model with ONLY Dense(1, input_shape=(D,))
# At least, until the bug is fixed
# https://github.com/keras-team/keras/issues/10417

model = tf.keras.models.load_model('linear_classification.h5')
print(model.layers)
model.evaluate(X_test, y_test)

# Download the file - requires Chrome (at this point)
from google.colab import files
files.download('linear_classification.h5')

